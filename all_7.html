<!doctype html>
<html class="no-js" lang="en">
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?fdc936c9f5a3b72177541183cdeb8cb3";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  techlarry
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="techlarry" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:larryim.cc ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_self" href="about.html">About</a></li>
        
        <li id=""><a target="_self" href="category.html">Category</a></li>
        
        <li id=""><a target="_self" href="notebook.html">NoteBook</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; techlarry</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_self" href="about.html">About</a></li>
        
        <li><a target="_self" href="category.html">Category</a></li>
        
        <li><a target="_self" href="notebook.html">NoteBook</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="Leetcode.html">Leetcode</a></li>
        
            <li><a href="C/C++.html">C/C++</a></li>
        
            <li><a href="Python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95.html">PythonÊï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ï</a></li>
        
            <li><a href="Python%E7%89%B9%E6%80%A7.html">PythonÁâπÊÄß</a></li>
        
            <li><a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">Êú∫Âô®Â≠¶‰π†</a></li>
        
            <li><a href="Python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E4%B8%89%E7%BB%B4%E5%8F%AF%E8%A7%86%E5%8C%96.html">PythonÁßëÂ≠¶ËÆ°ÁÆó‰∏âÁª¥ÂèØËßÜÂåñ</a></li>
        
            <li><a href="English.html">English</a></li>
        
            <li><a href="Computer%20System.html">Computer System</a></li>
        
            <li><a href="Deep%20Learning.html">Deep Learning</a></li>
        
            <li><a href="Latex.html">Latex</a></li>
        
            <li><a href="%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html">Êìç‰ΩúÁ≥ªÁªü</a></li>
        
            <li><a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html">Linux Á≥ªÁªüÁºñÁ®ã</a></li>
        
            <li><a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html">Êï∞ÊçÆÂ∫ì</a></li>
        
            <li><a href="Tensorflow.html">Tensorflow</a></li>
        
            <li><a href="Big%20Data.html">Big Data</a></li>
        
            <li><a href="%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html">ÊñáÁåÆÈòÖËØª</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="15037532856914.html">
                
                  <h1>K-means clustering</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>Optimization objective:<br/>
\[J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_k)=\frac{1}{m}\sum^m_{i=1}\rVert x^{(i)}-\mu_{c^{(i)}}\rVert^2\]</p>

<p>Randomly initialize \(K\) cluster centroid \(\mu_1, \mu_2,...,\mu_k\)</p>

<p>Repeat{<br/>
    for \(i=1\) to \(m\)<br/>
    \( c^{(i)}=\) index (from 1 to \(K\) of cluster centroid closest to \(x^{(i)}\)</p>

<h3 id="toc_0">Random initialization</h3>

<p>Randomly pick \(K\) training examples, and set \(\mu_1, \mu_2,...,\mu_k\) equal to these \(K\) examples.</p>

<p>\[\text{For }i = 1 \text{  to  } 100 {\\<br/>
\text{    Randomly initialize K cluster centroid } \mu_1, \mu_2,...,\mu_k\\<br/>
\text{    Run K-means}\\<br/>
\text{    Compute cost function (distortion)}\\<br/>
}\\<br/>
\]</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/26</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>Êú∫Âô®Â≠¶‰π†</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15036679491914.html">
                
                  <h1>Feature Engineering</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>As the saying goes: garbage in, garbage out. Your system will only be capable of learn‚Äê ing if the training data contains enough relevant features and not too many irrelevant ones. A critical part of the success of a Machine Learning project is coming up with a good set of features to train on. This process, called feature engineering, involves:</p>

<ul>
<li><code>Feature selection</code>: selecting the most useful features to train on among existing features.</li>
<li><code>Feature extraction</code>: combining existing features to produce a more useful one (as we saw earlier, dimensionality reduction algorithms can help).</li>
<li><code>Creating new features</code> by gathering new data.</li>
</ul>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/25</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>Êú∫Âô®Â≠¶‰π†</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15035780907547.html">
                
                  <h1>TensorFlow(5): Vector and Matrix Product in Numpy and TensorFlow</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">Numpy</h2>

<p>Following are common vector and matrix product operations in Numpy, they are quite simple and straightforward:</p>

<ul>
<li><p>Inner Product   \(\quad a^Tb\quad \):  <code>np.inner()</code></p></li>
<li><p>Outer Product  \(\quad ab^T\quad \):  <code>np.outer()</code></p></li>
<li><p>Dot Product  \(\quad a \cdot b = \sum a_ib_i\quad \): <code>np.dot()</code></p></li>
<li><p>Elementwise Product  \(\quad c_i = a_ib_i\quad \): <code>np.multiply()</code></p></li>
</ul>

<p>Note: inner product is defined on vector spaces over a field ùïÇ (finite or infinite dimensional). Dot product refers specifically to the product of vectors in \(‚Ñù^n\)</p>

<p>The difference between the following implementations of the dot/inner/outer/elementwise product are demonstrated as follows:</p>

<pre><code class="language-python">W = np.ones((2, 7), dtype=&#39;float32&#39;)
x1 = [9, 2, 5, 0, 0, 7, 5]
x2 = [9, 2, 2, 9, 0, 9, 2]
print(&#39;vector dot product&#39;, np.dot(x1,x2)) # dot product
print(&#39;inner&#39;, np.inner(x1,x2)) # inner product
print(&#39;outter&#39;, np.outer(x1,x2)) # outter product
print(&#39;element-wsie&#39;, np.multiply(x1,x2)) # Element-wise product
print(&#39;matrix dot product&#39;, np.dot(W, x1)) # dot product
</code></pre>

<pre><code>dot for vector 168
inner 168
outter [[81 18 18 81  0 81 18]
 [18  4  4 18  0 18  4]
 [45 10 10 45  0 45 10]
 [ 0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0]
 [63 14 14 63  0 63 14]
 [45 10 10 45  0 45 10]]
element-wsie [81  4 10  0  0 63 10]
dot for matrix [ 28.  28.]
</code></pre>

<h2 id="toc_1">TensorFlow</h2>

<p>Vector inner/outer Product are a bit complex in TensorFlow. </p>

<pre><code class="language-python">import tensorflow as tf
import numpy as np

x = tf.Variable([[1, -2, 3]], tf.float32, name=&#39;x&#39;)
y = tf.Variable([[-1, 2, -3]], tf.float32, name=&#39;y&#39;)

## inner product
inner_product1 = tf.reduce_sum(tf.multiply(x, y))
inner_product2 = tf.matmul(x, y, transpose_a=False, transpose_b= True) # different from inner_product1

## outer product
outer_product2 = tf.matmul(x, y, transpose_a= True)

## matrix dot product
X = tf.constant(np.random.randn(3,3), name=&#39;X&#39;)
W = tf.constant(np.random.randn(3,3), name=&#39;W&#39;)
matrix_product = tf.matmul(W, X)

sess = tf.InteractiveSession()
init_op = tf.global_variables_initializer()

# run
sess.run(init_op)
print(sess.run(inner_product1))
print(sess.run(inner_product2))
print(sess.run(outer_product2))
print(sess.run(matrix_product))
</code></pre>

<pre><code>-14
[[-14]]
[[-1  2 -3]
 [ 2 -4  6]
 [-3  6 -9]]
[[-0.88722509 -0.94128018 -2.1999658 ]
 [-0.67967623  1.33193446 -0.75612585]
 [ 0.31741623  1.3271727  -0.04311113]]
</code></pre>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/24</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Tensorflow.html'>Tensorflow</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15035712266178.html">
                
                  <h1>Python `set`, `tuple`</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0"><code>set</code></h2>

<p>A <code>set</code> is an unordered collection with no duplicate elements. Basic uses include membership testing and eliminating duplicate entries. Set objects also support mathematical operations like <code>union</code>, intersection, difference, and symmetric difference.</p>

<p>Curly braces or the <code>set()</code> function can be used to create sets. Note: to create an empty set you have to use <code>set()</code>, not {}; the latter creates an empty dictionary, a data structure that we discuss in the next section.</p>

<pre><code class="language-python">&gt;&gt;&gt; basket = {&#39;apple&#39;, &#39;orange&#39;, &#39;apple&#39;, &#39;pear&#39;, &#39;orange&#39;, &#39;banana&#39;}
&gt;&gt;&gt; print(basket)                      # show that duplicates have been removed
{&#39;orange&#39;, &#39;banana&#39;, &#39;pear&#39;, &#39;apple&#39;}
&gt;&gt;&gt; &#39;orange&#39; in basket                 # fast membership testing
True
&gt;&gt;&gt; &#39;crabgrass&#39; in basket
False

&gt;&gt;&gt; # Demonstrate set operations on unique letters from two words
...
&gt;&gt;&gt; a = set(&#39;abracadabra&#39;)
&gt;&gt;&gt; b = set(&#39;alacazam&#39;)
&gt;&gt;&gt; a                                  # unique letters in a
{&#39;a&#39;, &#39;r&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;}
&gt;&gt;&gt; a - b                              # letters in a but not in b
{&#39;r&#39;, &#39;d&#39;, &#39;b&#39;}
&gt;&gt;&gt; a | b                              # letters in either a or b
{&#39;a&#39;, &#39;c&#39;, &#39;r&#39;, &#39;d&#39;, &#39;b&#39;, &#39;m&#39;, &#39;z&#39;, &#39;l&#39;}
&gt;&gt;&gt; a &amp; b                              # letters in both a and b
{&#39;a&#39;, &#39;c&#39;}
&gt;&gt;&gt; a ^ b                              # letters in a or b but not both
{&#39;r&#39;, &#39;d&#39;, &#39;b&#39;, &#39;m&#39;, &#39;z&#39;, &#39;l&#39;}
</code></pre>

<h2 id="toc_1"><code>tuple</code></h2>

<p>A <code>tuple</code> is an (<code>immutable</code>) ordered list of values. A <code>tuple</code> is in many ways similar to a list; one of the most important differences is that <code>tuple</code> can be used as keys in dictionaries and as elements of sets, while <code>list</code> cannot. Here is a trivial example:</p>

<pre><code class="language-python">d = {(x, x + 1): x for x in range(10)}  # Create a dictionary with tuple keys
t = (5, 6)        # Create a tuple
print(type(t))    # Prints &quot;&lt;class &#39;tuple&#39;&gt;&quot;
print(d[t])       # Prints &quot;5&quot;
print(d[(1, 2)])  # Prints &quot;1&quot;
</code></pre>

<p>A special problem is the construction of tuples containing 0 or 1 items: the syntax has some extra quirks to accommodate these. Empty tuples are constructed by an empty pair of parentheses; a tuple with one item is constructed by following a value with a comma (it is not sufficient to enclose a single value in parentheses). Ugly, but effective. For example:</p>

<pre><code class="language-python">&gt;&gt;&gt; empty = ()
&gt;&gt;&gt; singleton = &#39;hello&#39;,    # &lt;-- note trailing comma
&gt;&gt;&gt; len(empty)
0
&gt;&gt;&gt; len(singleton)
1
&gt;&gt;&gt; singleton
(&#39;hello&#39;,)
</code></pre>

<p>The tuple syntax is simple, if you separate some values with commas, you automatically have a tuple(called <code>tuple packing</code>),</p>

<pre><code>&gt;&gt;&gt; 1,2,3
(1, 2, 3)
</code></pre>

<h3 id="toc_2"><code>tuple</code> function</h3>

<p>The <code>tuple</code> function works in pretty much the same way as <code>list</code>: it takes one sequence argument and converts it to a <code>tuple</code>.</p>

<pre><code>&gt;&gt;&gt; tuple([1,2,3])
(1, 2, 3)
</code></pre>

<h3 id="toc_3">Performance</h3>

<p>Instantiation is almost an order of magnitude faster for the tuple, but item access is actually somewhat faster for the list! So if you&#39;re creating a few tuples and accessing them many many times, it may actually be faster to use lists instead.</p>

<pre><code class="language-python">$ python -m timeit &quot;x=(1,2,3,4,5,6,7,8)&quot;
10000000 loops, best of 3: 0.0388 usec per loop

$ python -m timeit &quot;x=[1,2,3,4,5,6,7,8]&quot;
1000000 loops, best of 3: 0.363 usec per loop

$ python -m timeit -s &quot;x=(1,2,3,4,5,6,7,8)&quot; &quot;y=x[3]&quot;
10000000 loops, best of 3: 0.0938 usec per loop

$ python -m timeit -s &quot;x=[1,2,3,4,5,6,7,8]&quot; &quot;y=x[3]&quot;
10000000 loops, best of 3: 0.0649 usec per loop
</code></pre>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/24</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Python%E7%89%B9%E6%80%A7.html'>PythonÁâπÊÄß</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="tensorflow_operation.html">
                
                  <h1>TensorFlow(4):TensorFlow Operation</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<ul>
<li>
<a href="#toc_0">1 Visualize with TensorBoard</a>
<ul>
<li>
<a href="#toc_1">Explicitly name operation, variable</a>
</li>
</ul>
</li>
<li>
<a href="#toc_2">2 Constant types</a>
<ul>
<li>
<a href="#toc_3">Tensors filled with a specific value</a>
</li>
<li>
<a href="#toc_4">Constants as sequences</a>
</li>
</ul>
</li>
<li>
<a href="#toc_5">3 Math Operations</a>
</li>
<li>
<a href="#toc_6">4 TensorFlow data types:</a>
<ul>
<li>
<a href="#toc_7">Python Native Types</a>
</li>
<li>
<a href="#toc_8">TensorFlow Native Types</a>
</li>
<li>
<a href="#toc_9">Numpy Data Types</a>
</li>
<li>
<a href="#toc_10">Constant</a>
</li>
<li>
<a href="#toc_11">Variables</a>
<ul>
<li>
<a href="#toc_12">Each session maintains its own copy of variable</a>
</li>
<li>
<a href="#toc_13">Use a variable to initialize another variables</a>
</li>
<li>
<a href="#toc_14">Session vs InteractiveSession,</a>
</li>
</ul>
</li>
<li>
<a href="#toc_15">Placeholder</a>
</li>
<li>
<a href="#toc_16">Lazy loading</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">1 Visualize with TensorBoard</h2>

<pre><code class="language-python">import tensorflow as tf
a = tf.constant(2, name=&#39;a&#39;)
b = tf.constant(3, name=&#39;b&#39;)
x = tf.add(a, b, name=&#39;add&#39;)
with tf.Session() as sess:
    writer = tf.summary.FileWriter(&#39;./graphs&#39;, sess.graph)
    print(sess.run(x))media/15033836099887
writer.close() # close the writer when you&#39;re done using it.
</code></pre>

<pre><code>5
</code></pre>

<p>Bash command (to view TensorBoard):</p>

<pre><code class="language-bash"> tensorboard --logdir=&#39;./graphs&#39; --port 6006
 # open http://localhost:6006/#graphs in your browser
</code></pre>

<h3 id="toc_1">Explicitly name operation, variable</h3>

<pre><code class="language-python">a = tf.constant(2, name=&#39;a&#39;)
b = tf.constant(3, name=&#39;b&#39;)
x = tf.add(a,b,name=&#39;add&#39;)
with tf.Session() as sess:
    writer = tf.summary.FileWriter(&#39;./graphs&#39;, sess.graph)
    print(sess.run(x))
writer.close() # close the writer when you&#39;re done using it.
</code></pre>

<pre><code>5
</code></pre>

<p>The figure produced by TensorBoard is as follows:</p>

<p><img src="media/15033836099887/explicit_name.png" alt=""/></p>

<p><strong>Note</strong>:  Learn to use TensorBoard well and often. It will help a lot when you build complicated models.</p>

<h2 id="toc_2">2 Constant types</h2>

<h3 id="toc_3">Tensors filled with a specific value</h3>

<p>Using <code>tensorflow.zeros</code> to fill tensor with zeros, which is similar to <code>Numpy</code>:</p>

<pre><code class="language-python">tf.zeros(shape, dtype=tf.float32, name=None)
</code></pre>

<p>For example,</p>

<pre><code class="language-python">x = tf.zeros([2,3], tf.int32)
with tf.Session() as sess:
    print(sess.run(x))
</code></pre>

<pre><code>[[0 0 0]
 [0 0 0]]
</code></pre>

<p><code>tensorflow.zeros_like</code> return an tensor of zeros with the same shape and type as a given tensor. For example, we may want to have a tensor filled with zeros, with the same shape as <code>x</code>:</p>

<pre><code class="language-python">y = tf.zeros_like(x)
with tf.Session() as sess:
    print(sess.run(y))
</code></pre>

<pre><code>[[0 0 0]
 [0 0 0]]
</code></pre>

<p>There are other command to fill tensor with a specific value, such as <code>tensorflow.ones</code>, <code>tensorflow.ones_like</code>, which of usage is similar to <code>tensorflow.zeros</code>, <code>tensorflow.zeros_like</code>.</p>

<p><code>tensorflow.fill</code> creates a tensor filled with a scalar value:</p>

<pre><code class="language-python">tf.fill(dims, value, name=None)
</code></pre>

<pre><code class="language-python">z = tf.fill([3,4],3)
with tf.Session() as sess:
    print(sess.run(z))
</code></pre>

<pre><code>[[3 3 3 3]
 [3 3 3 3]
 [3 3 3 3]]
</code></pre>

<h3 id="toc_4">Constants as sequences</h3>

<p>You can create constants that are sequences, using <code>tf.linspace</code>, <code>tf.range</code>:</p>

<pre><code class="language-python">tf.linspace(start, stop, num, name=None)

# create a sequence of num evenly-spaced values are generated beginning at  start. If num &gt; 1, the values in the sequence increase by stop - start / num - 1, so that the last one is exactly stop.
# start, stop, num must be scalars
# comparable to but slightly different from numpy.linspace
# numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)

tf.range(start, limit=None, delta=1, dtype=None, name=&#39;range&#39;)
# create a sequence of numbers that begins at start and extends by increments of delta up to but not including limit
# slight different from range in Python
</code></pre>

<pre><code class="language-python">x = tf.linspace(10.0, 13.0, 4, name=&#39;linspace&#39;)
y = tf.range(3, 18)
z= tf.range(3, 18, 3)
with tf.Session() as sess:
    print(sess.run(x))
    print(sess.run(y))
    print(sess.run(z))
</code></pre>

<pre><code>[ 10.  11.  12.  13.]
[ 3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]
[ 3  6  9 12 15]
</code></pre>

<h2 id="toc_5">3 Math Operations</h2>

<p><img src="media/15033836099887/math_operations.png" alt=""/></p>

<pre><code class="language-python">a = tf.constant([[3,6],[0,0]])
b = tf.constant([[0,0],[2,2]])
x1 = tf.add(a, b)
x2 = tf.add_n([a,b,b]) # &gt;&gt; [7 10]. Equivalent to a + b + b
x3 = tf.multiply(a, b) # &gt;&gt; [6 12] because mul is element wise
x4 = tf.matmul(a, b) # &gt;&gt; ValueError
x5 = tf.matmul(tf.reshape(a, [4, 1]), tf.reshape(b, [1, 4])) # &gt;&gt; [[18]]

with tf.Session() as sess:
    sess.run(a)
    sess.run(b)
    print(&#39;x1:\n&#39;, sess.run(x1))
    print(&#39;x2:\n&#39;, sess.run(x2))
    print(&#39;x3:\n&#39;, sess.run(x3))
    print(&#39;x4:\n&#39;, sess.run(x4))
    print(&#39;x5:\n&#39;, sess.run(x5))
</code></pre>

<pre><code>x1:
 [[3 6]
 [2 2]]
x2:
 [[3 6]
 [4 4]]
x3:
 [[0 0]
 [0 0]]
x4:
 [[12 12]
 [ 0  0]]
x5:
 [[ 0  0  6  6]
 [ 0  0 12 12]
 [ 0  0  0  0]
 [ 0  0  0  0]]
</code></pre>

<h2 id="toc_6">4 TensorFlow data types:</h2>

<h3 id="toc_7">Python Native Types</h3>

<p>TensorFlow takes Python natives types: <code>boolean</code>, <code>numeric</code> (<code>int</code>, <code>float</code>), <code>strings</code></p>

<p>TensorFlow takes in Python native types such as Python boolean values, numeric values (integers, floats), and strings. Single values will be converted to 0-d tensors (or scalars), lists of values will be converted to 1-d tensors (vectors), lists of lists of values will be converted to 2-d tensors (matrices), and so on.</p>

<pre><code class="language-python">tf.InteractiveSession() # open tensorflow interactivesession
t_0 = 19   # Treated as a 0-d tensor, or &quot;scalar&quot; 
print(&#39;t_0:&#39;,t_0)
print(tf.zeros_like(t_0))   # ==&gt; 0
print(tf.ones_like(t_0))   # ==&gt; 1
t_1 = [b&quot;apple&quot; ,  b&quot;peach&quot; ,  b&quot;grape&quot;]   # treated as a 1-d tensor, or &quot;vector&quot; 
print(&#39;t_1:&#39;,t_1)
print(tf.zeros_like(t_1))   # ==&gt; [&#39;&#39; &#39;&#39; &#39;&#39;]
t_2= [[ True, False, False],  [False, False, True], [False, True ,   False ]]   # treated as a 2-d tensor, or &quot;matrix&quot;
print(&#39;t_2:&#39;,t_2)
print(tf.zeros_like(t_2))   # ==&gt; 2x2 tensor, all elements are False 
print(tf.ones_like(t_2))   # ==&gt; 2x2 tensor, all elements are True
</code></pre>

<pre><code>t_0: 19
Tensor(&quot;zeros_like_32:0&quot;, shape=(), dtype=int32)
Tensor(&quot;ones_like_20:0&quot;, shape=(), dtype=int32)
t_1: [b&#39;apple&#39;, b&#39;peach&#39;, b&#39;grape&#39;]
Tensor(&quot;zeros_like_33:0&quot;, shape=(3,), dtype=string)
t_2: [[True, False, False], [False, False, True], [False, True, False]]
Tensor(&quot;zeros_like_34:0&quot;, shape=(3, 3), dtype=bool)
Tensor(&quot;ones_like_21:0&quot;, shape=(3, 3), dtype=bool)
</code></pre>

<p><strong>Note: Do not use Python native types for tensors because TensorFlow has to infer Python type.</strong></p>

<h3 id="toc_8">TensorFlow Native Types</h3>

<p>Like <code>NumPy</code>, <code>TensorFlow</code> also its own data types such as <code>tf.int32</code>, <code>tf.float32</code>. Below is a list of current TensorFlow data types.</p>

<p><img src="media/15033836099887/tensorflow_data_types.png" alt=""/></p>

<h3 id="toc_9">Numpy Data Types</h3>

<p>By now, you‚Äôve probably noticed the similarity between <code>NumPy</code> and <code>TensorFlow</code>. <code>TensorFlow</code> was designed to integrate seamlessly with <code>Numpy</code>, the package that has become the  lingua franca of data science.</p>

<p>TensorFlow‚Äôs data types are based on those of NumPy; in fact, <code>np.int32 == tf.int32</code> returns <code>True</code>. You can pass <code>NumPy</code> types to <code>TensorFlow</code> ops.</p>

<p>Example:</p>

<pre><code class="language-python">import numpy as np
tf.ones([2, 2],  np.float32)
</code></pre>

<pre><code>&lt;tf.Tensor &#39;ones:0&#39; shape=(2, 2) dtype=float32&gt;
</code></pre>

<pre><code class="language-python">x = np.zeros((2,2))
tf.ones_like(x)
</code></pre>

<pre><code>&lt;tf.Tensor &#39;ones_like_22:0&#39; shape=(2, 2) dtype=float64&gt;
</code></pre>

<h3 id="toc_10">Constant</h3>

<p>Constants are stored in the graph definition. This makes loading graphs expensive when constants are big. <strong>Only use constants for primitive types, use variables or readers for more data that requires more memory</strong>.</p>

<pre><code class="language-python">g = tf.Graph() # to add operators to a graph, set it as default:
with g.as_default():
    my_const = tf.constant([1.0, 2.0], name=&quot;my_const&quot;)
    with tf.Session() as sess:
        print(sess.graph.as_graph_def())
</code></pre>

<pre><code>node {
  name: &quot;my_const&quot;
  op: &quot;Const&quot;
  attr {
    key: &quot;dtype&quot;
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: &quot;value&quot;
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: &quot;\000\000\200?\000\000\000@&quot;
      }
    }
  }
}
versions {
  producer: 24
}
</code></pre>

<h3 id="toc_11">Variables</h3>

<p><code>tf.constant</code> is an operation, but <code>tf.Variable</code> is a class. <code>tf.Variables</code> holds several operations:</p>

<pre><code class="language-python">tf.InteractiveSession()
xx = tf.Variable(23, name=&#39;scalar&#39;)
xx.initializer # init op
xx.value() # read op
assign_op = xx.assign(5)

</code></pre>

<p>You have to initialize <code>variables</code>, The easiest way is initializing all variables at once:</p>

<pre><code class="language-python">init = tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run(init)
    print(xx.eval())
    sess.run(assign_op)
    print(xx.eval())
</code></pre>

<pre><code>23
5
</code></pre>

<h4 id="toc_12">Each session maintains its own copy of variable</h4>

<pre><code class="language-python">W = tf.Variable(10, name=&#39;W&#39;)
sess1 = tf.Session()
sess2 = tf.Session()
sess1.run(W.initializer)
sess2.run(W.initializer)
print(sess1.run(W.assign_add(10)))
print(sess2.run(W.assign_sub(2))) # not 18!

sess1.close()
sess2.close()
</code></pre>

<pre><code>20
8
</code></pre>

<h4 id="toc_13">Use a variable to initialize another variables</h4>

<pre><code class="language-python"># want to declare U = 2*W
# W is random tensor
W = tf.Variable(tf.truncated_normal([4, 2]))
U = tf.Variable(2*W.initialized_value())
with tf.Session() as sess:
    sess.run(U.initializer)
    print(U.eval())
</code></pre>

<pre><code>[[ 1.11442947 -3.1675539 ]
 [ 3.02267933 -0.81786388]
 [ 2.57613969 -0.98440802]
 [ 0.6298722  -0.38194153]]
</code></pre>

<h4 id="toc_14">Session vs InteractiveSession,</h4>

<p>You sometimes see InteractiveSession instead of Session. The only difference is an InteractiveSession makes itself the default.</p>

<pre><code class="language-python">sess = tf.InteractiveSession()
a = tf.constant(5.0)
b = tf.constant(6.0)
c = a*b
# We can just use `c.eval()` with out specifying the context `sess`
print(c.eval())
sess.close()
</code></pre>

<pre><code>30.0
</code></pre>

<h3 id="toc_15">Placeholder</h3>

<p>A TensorFlow program often has 2 phases:</p>

<ol>
<li>Assemble a graph</li>
<li>Use a session to execute operations in the graph</li>
</ol>

<p>\(\rightarrow\) can assemble the graph without knowing the values needed for computation</p>

<p><strong>Analogy</strong>: Can define the function \(f(x,y) = x*2+y\) without knowing value of \(x\) or \(y\).</p>

<p>So using <code>placeholders</code>, we can later supply their data when they needed to execute the computation.</p>

<pre><code>tf.placeholder(dtype, shape=None, name=None)
</code></pre>

<p><code>shape=None</code> means that tensor of nay shape will be accepted as value for placeholder. Note: <strong><code>shape=None</code> is easy to construct graphs, but nightmarish for debugging</strong>.</p>

<p>To make <code>shape</code>  flexible, <code>None</code> can be used in the <code>shape</code> argument:</p>

<pre><code>    X = tf.placeholder(dtype=tf.float32, shape=[n_x, None], name=&#39;X&#39;)
</code></pre>

<h3 id="toc_16">Lazy loading</h3>

<p><code>Lazy loading</code> means defer creating/initializing an object until it is needed. In the context of TensorFlow, it means you defer creating an op until you need to compute it. </p>

<p>Normal loading:</p>

<pre><code class="language-python">g = tf.Graph()
with g.as_default():
    x = tf.Variable(10, name=&#39;x&#39;)
    y = tf.Variable(20, name=&#39;y&#39;)
    z = tf.add(x,y) # you create the node for add node before executing the graph

    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for _ in range(10):
            sess.run(z)

</code></pre>

<p>Lazy loading:</p>

<pre><code class="language-python">g = tf.Graph()
with g.as_default():
    x = tf.Variable(10, name=&#39;x&#39;)
    y = tf.Variable(20, name=&#39;y&#39;)

    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        writer = tf.summary.FileWriter(&#39;./my_graph/12&#39;, sess.graph)
        for _ in range(10):
            sess.run(tf.add(x,y)) # someone decides to be clever to save one line of code
        writer.close()
</code></pre>

<p>Note: In Lazy loading, Node <code>ADD</code> added 10 times to the graph definition. Image you want to compute an operations thousands of times, you graph gets bloated slow to load, and expensive to pass around.</p>

<p><strong>Solution</strong>: </p>

<ol>
<li>Separate definition of ops from computing/running ops</li>
<li>Use Python property to ensure function is also loaded once the first time it is called.</li>
</ol>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/8/20</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Tensorflow.html'>Tensorflow</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   <a href="all_6.html">&laquo; Prev Page</a>  
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			 <a href="all_8.html">&raquo; Next Page</a> 
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="http://or9a8nskt.bkt.clouddn.com/figure.jpeg" /></div>
            
                <h1>techlarry</h1>
                <div class="site-des">‰ªñÂ±±‰πãÁü≥ÔºåÂèØ‰ª•ÊîªÁéâ</div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="https://github.com/techlarry" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:wang.zhen.hua.larry@gmail.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="Leetcode.html"><strong>Leetcode</strong></a>
        
            <a href="C/C++.html"><strong>C/C++</strong></a>
        
            <a href="Python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95.html"><strong>PythonÊï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ï</strong></a>
        
            <a href="Python%E7%89%B9%E6%80%A7.html"><strong>PythonÁâπÊÄß</strong></a>
        
            <a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>Êú∫Âô®Â≠¶‰π†</strong></a>
        
            <a href="Python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E4%B8%89%E7%BB%B4%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>PythonÁßëÂ≠¶ËÆ°ÁÆó‰∏âÁª¥ÂèØËßÜÂåñ</strong></a>
        
            <a href="English.html"><strong>English</strong></a>
        
            <a href="Computer%20System.html"><strong>Computer System</strong></a>
        
            <a href="Deep%20Learning.html"><strong>Deep Learning</strong></a>
        
            <a href="Latex.html"><strong>Latex</strong></a>
        
            <a href="%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html"><strong>Êìç‰ΩúÁ≥ªÁªü</strong></a>
        
            <a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html"><strong>Linux Á≥ªÁªüÁºñÁ®ã</strong></a>
        
            <a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html"><strong>Êï∞ÊçÆÂ∫ì</strong></a>
        
            <a href="Tensorflow.html"><strong>Tensorflow</strong></a>
        
            <a href="Big%20Data.html"><strong>Big Data</strong></a>
        
            <a href="%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB.html"><strong>ÊñáÁåÆÈòÖËØª</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="scalable%20machine%20learning.html">Scalable Machine Learning</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15108128842368.html">`MLlib`: Machine Learning in Apache Spark</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="introdution_to_big_data.html">Introduction to big data</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="Spark_introduction.html">Spark</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="hardware/software_interface.html">Hardware/Software Interface</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    <script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
