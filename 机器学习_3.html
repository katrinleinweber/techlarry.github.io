<!doctype html>
<html class="no-js" lang="en">
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?fdc936c9f5a3b72177541183cdeb8cb3";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  机器学习 - techlarry
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="techlarry" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:larryim.cc ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_self" href="about.html">About</a></li>
        
        <li id=""><a target="_self" href="category.html">Category</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; techlarry</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        
        <li><a target="_self" href="about.html">About</a></li>
        
        <li><a target="_self" href="category.html">Category</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="Leetcode.html">Leetcode</a></li>
        
            <li><a href="C/C++.html">C/C++</a></li>
        
            <li><a href="Python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95.html">Python数据结构与算法</a></li>
        
            <li><a href="Python%E7%89%B9%E6%80%A7.html">Python特性</a></li>
        
            <li><a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">机器学习</a></li>
        
            <li><a href="Python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E4%B8%89%E7%BB%B4%E5%8F%AF%E8%A7%86%E5%8C%96.html">Python科学计算三维可视化</a></li>
        
            <li><a href="English.html">English</a></li>
        
            <li><a href="Computer%20System.html">Computer System</a></li>
        
            <li><a href="Deep%20Learning.html">Deep Learning</a></li>
        
            <li><a href="Latex.html">Latex</a></li>
        
            <li><a href="%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html">操作系统</a></li>
        
            <li><a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html">Linux 系统编程</a></li>
        
            <li><a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html">数据库</a></li>
        
            <li><a href="Tensorflow.html">Tensorflow</a></li>
        
            <li><a href="Data%20Science.html">Data Science</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="14972614146835.html">
                
                  <h1>Machine Learning (2): Linear Regression with Multiple Variables</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<ul>
<li>
<a href="#toc_0">Multiple Features (variables)</a>
</li>
<li>
<a href="#toc_1">Gradient descent</a>
<ul>
<li>
<a href="#toc_2">Feature Scaling</a>
</li>
<li>
<a href="#toc_3">Learning rate</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">Computing Parameters Analytically</a>
<ul>
<li>
<a href="#toc_5">Normal equation:</a>
</li>
<li>
<a href="#toc_6">Gradient descent v.s. Normal equation</a>
</li>
<li>
<a href="#toc_7">Normal Equation Non-invertible</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">Multiple Features (variables)</h2>

<p>Notation:<br/>
\(m\) = the number of training examples<br/>
\(n\) = the number of features<br/>
\(x^{(i)}\)  = the input (feature) of \(i^{th}\) training example<br/>
\(x^{(i)}_j\) =  value of feature \(j\) of \(i^{th}\) training example</p>

<p>The multivariable form of the hypothesis function accommodating these multiple features is as follows:</p>

<p>\[h_θ(x)=θ_0+θ_1x_1+θ_2x_2+θ_3x_3+⋯+θ_nx_n=\theta^Tx\] (\(n+1\)- dimensional vector)</p>

<p>For convenience of notation, define \(x_0=1\)</p>

<h2 id="toc_1">Gradient descent</h2>

<p><strong>Hypothesis</strong>: <br/>
\[h_\theta(x) = \theta^Tx\]</p>

<p><strong>Parameters</strong>:<br/>
\[\theta\]</p>

<p><strong>Cost Function</strong>:<br/>
\[J(\theta)=\frac{1}{2m}\Sigma^m_{i=1}(h_\theta(x^{(i)})-y^{(i)})^2\]</p>

<p><strong>Gradient descent</strong>:<br/>
Repeat until converge{</p>

<p>\(\theta_j := \theta_j -\alpha\frac{\partial}{\partial \theta_j}J(\theta)=\theta_j -\alpha\frac{1}{m}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\)  (simultaneously update for every j= 0,1,...,n)</p>

<h3 id="toc_2">Feature Scaling</h3>

<p>We can speed up gradient descent by having each of our input values in roughly the same range. This is because \(\theta\) will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.</p>

<p><strong>Idea: Make sure features are on a similar scale.</strong></p>

<p>Two techniques to help with this are <strong>feature scaling</strong> and <strong>mean normalization</strong>.</p>

<ul>
<li><p><strong>Feature scaling</strong> involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable, resulting in a new range of just 1. </p></li>
<li><p><strong>Mean normalization</strong> involves subtracting the average value for an input variable from the values for that input variable resulting in a new average value for the input variable of just zero. </p></li>
</ul>

<p>Replace \(x_i\) with \( x_i -\mu_i\) to make features have approximately zero mean (Do not apply to \(x_0=1\))</p>

<p>\[x_i =\frac{ x_i - \mu_i}{S_i}\]</p>

<p>where  \(\mu_i\) is average value of \(x_i\) in training set, \(S_i\) is the range (max-min) or standard deviation of \(x_i\).</p>

<p>E.g. \[x_1=\frac{size-1000}{2000}\]<br/>
\[x_2=\frac{\#bedrooms-2}{5}\]</p>

<h3 id="toc_3">Learning rate</h3>

<p><strong>Debugging</strong>: How to make sure gradient descent is working correctly.</p>

<p>-- How to choose learning rate \(\alpha\).</p>

<p>Gradient descent is working correctly if \(J(\theta)\) decreases after every iteration.</p>

<p>Use smaller \(\alpha\). For sufficiently small \(\alpha\), \(J(\theta)\) should decrease on every iteration.</p>

<p><strong>Automatic convergence test</strong>. Declare convergence if \(J(\theta)\) decreases by less than \(E\) in one iteration, where \(E\) is some small value such as \(10^{−3}\). However in practice it&#39;s difficult to choose this threshold value.</p>

<p><strong>Summary</strong>:</p>

<ul>
<li>If  \(\alpha\)  is too small: slow convergence.</li>
<li>If \(\alpha\) is too large: may not decrease on every iteration; may not converge.</li>
</ul>

<h2 id="toc_4">Computing Parameters Analytically</h2>

<h3 id="toc_5">Normal equation:</h3>

<p>Gradient descent gives one way of minimizing \(J\). The &quot;Normal Equation&quot; method minimizes \(J\) by explicitly taking its derivatives with respect to the \(θj\) ’s, and setting them to zero. This allows us to find the optimum theta without iteration. The normal equation formula is given below:</p>

<p>\[\theta = (X^TX)^{-1}X^Ty\]</p>

<p>Matlab command: </p>

<pre><code class="language-Matlab">pinv(X&#39;*X)*X&#39;*y
</code></pre>

<p>where <code>pinv</code> is <code>peudoinversion</code> of matrix. It is different to <code>inv</code>.</p>

<h3 id="toc_6">Gradient descent v.s. Normal equation</h3>

<p><img src="media/14972614146835/Screen%20Shot%202017-06-27%20at%202.38.45%20PM.png" alt="Screen Shot 2017-06-27 at 2.38.45 P"/></p>

<h3 id="toc_7">Normal Equation Non-invertible</h3>

<p>The common reason causes non-invertible:</p>

<ul>
<li>Redundant features(linearly dependent)
E.g. \(x_1\) = size in feet\(^2\), \(x_2\) = size in m\(^2\)</li>
<li>Too many features(e.g. \(m&lt;=n\)).
-- Delete some features, or use regularization.</li>
</ul>

<p>where \(m\) is the number of training examples, \(n\) is the number of features.</p>

<p>Solutions to the above problems include deleting a feature that is linearly dependent with another or deleting one or more features when there are too many features.</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/6/12</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>机器学习</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14970886401689.html">
                
                  <h1>Machine Learning (1): Introduction to Machine Learning</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<ul>
<li>
<a href="#toc_0">Definition</a>
</li>
<li>
<a href="#toc_1">Examples</a>
</li>
<li>
<a href="#toc_2">Machine learning algorithms</a>
</li>
<li>
<a href="#toc_3">Supervised learning</a>
<ul>
<li>
<a href="#toc_4">Example</a>
</li>
</ul>
</li>
<li>
<a href="#toc_5">Unsupervised Learning</a>
</li>
<li>
<a href="#toc_6">Cost Function</a>
</li>
<li>
<a href="#toc_7">Gradient descent</a>
</li>
</ul>


<h2 id="toc_0">Definition</h2>

<p>Arthur Samuel(1959). Machine Learning: A Field of study that gives computers the ability to learn without being explicitly programmed.</p>

<p>Tom Mitchell(1998) Well-posed Learning Problem: A computer program is said to learn from experience <code>E</code> with respect to some task <code>T</code> and some performance measure <code>P</code>, if its performance on <code>T</code>, as measured by <code>P</code>, improves with experience <code>E</code>.</p>

<p>In general, any machine learning problem can be assigned to one of two broad classifications:</p>

<p><strong>Supervised learning</strong> and <strong>Unsupervised learning</strong>.</p>

<h2 id="toc_1">Examples</h2>

<ul>
<li><p>Database mining</p>

<p>Large datasets from growth of automation/web<br/>
E.g, Web click data, medical records, biology, engineering</p></li>
<li><p>Applications can&#39;t program by hand</p>

<p>E.g., Autonomous helicopter, handwriting recognition, most of Natural Language Processing( NLP), Computer Vision</p></li>
<li><p>Self-customizing programs</p>

<p>E.g. Amazon, Netflix product recommendations</p></li>
<li><p>Understanding human learning (brain, real AI)</p></li>
</ul>

<h2 id="toc_2">Machine learning algorithms</h2>

<ul>
<li>Supervised learning</li>
<li>Unsupervised learning</li>
<li>Reinforcement learning</li>
<li>Recommender systems</li>
</ul>

<h2 id="toc_3">Supervised learning</h2>

<p>In  supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.</p>

<ul>
<li><strong>Regression problem</strong>: Predict continuous valued output (eg.price)</li>
<li><strong>classification problem</strong>: Predict discrete valued output (eg. tumor or not)</li>
</ul>

<h3 id="toc_4">Example</h3>

<p>Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a continuous output, so this is a regression problem.</p>

<p>We could turn this example into a classification problem by instead making our output about whether the house &quot;sells for more or less than the asking price.&quot; Here we are classifying the houses based on price into two discrete categories.</p>

<p><img src="media/14970886401689/Screen%20Shot%202017-06-12%20at%2010.15.14%20AM.png" alt="Screen Shot 2017-06-12 at 10.15.14 A"/></p>

<h2 id="toc_5">Unsupervised Learning</h2>

<p>Unsupervised learning is the task of making an inference from data without the “correct answers” given (unlabeled data). With unsupervised learning there is no feedback based on the prediction results.</p>

<h2 id="toc_6">Cost Function</h2>

<p>We can measure the accuracy of our hypothesis function by using a <strong>cost function</strong>. </p>

<p><strong>Idea</strong>: Choose \(\theta_0, \theta_1\) so that \(h_\theta(x)\) is close to \(y\) for our training examples (x,y)</p>

<p><strong>Hypothesis</strong>: <br/>
\[h_\theta(x) = \theta_0+\theta_1x \]</p>

<p><strong>Parameters</strong>:<br/>
\[\theta_0, \theta_1\]</p>

<p><strong>Cost Function</strong>:<br/>
\[J(\theta_0, \theta_1)=\frac{1}{2m}\Sigma^m_{i=1}(h_\theta(x^{(i)})-y^{(i)})^2\]</p>

<p>This function is otherwise called the &quot;Squared error function&quot;, or &quot;Mean squared error&quot;. </p>

<p><strong>Goal</strong>:<br/>
\[ \min \limits_{\theta_0,\theta_1} J(\theta_0, \theta_1) \]</p>

<h2 id="toc_7">Gradient descent</h2>

<p>Have some function Goal: \(J(\theta_0, \theta_1) \)</p>

<p>Want \( \min \limits_{\theta_0,\theta_1} J(\theta_0, \theta_1) \)</p>

<p><strong>Outline</strong>:</p>

<ul>
<li>Start with some \(\theta_0,\theta_1\)</li>
<li>Keep changing \(\theta_0,\theta_1\) to reduce \(J(\theta_0,\theta_1)\) until we hopefully end up at a minimum</li>
</ul>

<p><strong>Gradient descent algorithm</strong>:<br/>
repeat until converge{</p>

<p>\(\theta_j := \theta_j -\alpha\frac{\partial}{\partial \theta_j}J(\theta_0,\theta_1)\)  (for \(j=0\) and \(j=1\))</p>

<p>注：</p>

<ol>
<li><code>:=</code> is assignment, not truth assertion</li>
</ol>

<p>2.At each iteration j, one should simultaneously update the parameters \(\theta_0,\theta_1\). Updating a specific parameter prior to calculating another one on the j(th) iteration would yield to a wrong implementation.</p>

<p>\(temp0 := \theta_0 -\alpha\frac{\partial}{\partial \theta_0}J(\theta_0,\theta_1)\)</p>

<p>\(temp1 := \theta_1 -\alpha\frac{\partial}{\partial \theta_1}J(\theta_0,\theta_1)\)</p>

<p>\(\theta_0:=temp0\)<br/>
\(\theta_1:=temp1\)</p>

<ol>
<li>\(\alpha\) is learning rate: if \(\alpha\) is too small, gradient descent can be slow. If \(\alpha\)  is too large, gradient descent can overshoot the minimum. It may fail to converge, or even diverge.</li>
<li>As we approach a local minimum, gradient descent will automatically take smaller steps. So, no need to decrease \(\alpha\) over time.</li>
</ol>

<p>convex function(often Bowl shaped function)</p>

<p><strong>Batch Gradient Descent</strong>: Each step of gradient descent uses all the training examples.</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/6/10</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>机器学习</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   <a href="机器学习_2.html">&laquo; Prev Page</a>  
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="http://or9a8nskt.bkt.clouddn.com/figure.jpeg" /></div>
            
                <h1>techlarry</h1>
                <div class="site-des">他山之石，可以攻玉</div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="https://github.com/techlarry" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:wang.zhen.hua.larry@gmail.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="Leetcode.html"><strong>Leetcode</strong></a>
        
            <a href="C/C++.html"><strong>C/C++</strong></a>
        
            <a href="Python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95.html"><strong>Python数据结构与算法</strong></a>
        
            <a href="Python%E7%89%B9%E6%80%A7.html"><strong>Python特性</strong></a>
        
            <a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html"><strong>机器学习</strong></a>
        
            <a href="Python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E4%B8%89%E7%BB%B4%E5%8F%AF%E8%A7%86%E5%8C%96.html"><strong>Python科学计算三维可视化</strong></a>
        
            <a href="English.html"><strong>English</strong></a>
        
            <a href="Computer%20System.html"><strong>Computer System</strong></a>
        
            <a href="Deep%20Learning.html"><strong>Deep Learning</strong></a>
        
            <a href="Latex.html"><strong>Latex</strong></a>
        
            <a href="%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html"><strong>操作系统</strong></a>
        
            <a href="Linux%20%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B.html"><strong>Linux 系统编程</strong></a>
        
            <a href="%E6%95%B0%E6%8D%AE%E5%BA%93.html"><strong>数据库</strong></a>
        
            <a href="Tensorflow.html"><strong>Tensorflow</strong></a>
        
            <a href="Data%20Science.html"><strong>Data Science</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="C++baics.html">C++ Basics</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15091487975421.html">C 语言的各种版本</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="hardware/software_interface.html">Hardware/Software Interface</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15089188725996.html">Linux 内存布局</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15089186263565.html">Valgrind</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    <script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
