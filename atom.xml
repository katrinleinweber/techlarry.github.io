<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[techlarry]]></title>
  <link href="http://larryim.cc/atom.xml" rel="self"/>
  <link href="http://larryim.cc/"/>
  <updated>2018-07-18T13:42:23+08:00</updated>
  <id>http://larryim.cc/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[Operating System Concepts 3 - Processes]]></title>
    <link href="http://larryim.cc/os-concets-processes.html"/>
    <updated>2018-07-17T00:28:20+08:00</updated>
    <id>http://larryim.cc/os-concets-processes.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">1 Process concept</a>
<ul>
<li>
<a href="#toc_1">1.1 The process</a>
</li>
<li>
<a href="#toc_2">1.2 Process state 进程状态</a>
</li>
<li>
<a href="#toc_3">1.3 Process control block</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">2 Process scheduling 进程调度</a>
<ul>
<li>
<a href="#toc_5">2.1 Scheduling Queues</a>
</li>
<li>
<a href="#toc_6">2.2 context switch</a>
</li>
</ul>
</li>
<li>
<a href="#toc_7">3 Operating on Processes</a>
<ul>
<li>
<a href="#toc_8">3.1 Process creation</a>
</li>
<li>
<a href="#toc_9">3.2 Process termintation</a>
</li>
</ul>
</li>
<li>
<a href="#toc_10">4 Interprocess communication</a>
</li>
<li>
<a href="#toc_11">5 IPC in shared-memory system</a>
</li>
<li>
<a href="#toc_12">6 IPC in message-passing system</a>
<ul>
<li>
<a href="#toc_13">6.1 Direct/Indirect communication</a>
<ul>
<li>
<a href="#toc_14">(1) Direct Communication</a>
</li>
<li>
<a href="#toc_15">(2) Indirect Communication**</a>
</li>
</ul>
</li>
<li>
<a href="#toc_16">6.2 Synchronization</a>
</li>
<li>
<a href="#toc_17">6.3 Buffering</a>
</li>
</ul>
</li>
<li>
<a href="#toc_18">7 Examples of IPC</a>
<ul>
<li>
<a href="#toc_19">7.1 Mach Message Passing</a>
</li>
<li>
<a href="#toc_20">7.2 Pipes</a>
<ul>
<li>
<a href="#toc_21">(1) Ordinary pipes</a>
</li>
<li>
<a href="#toc_22">(2) Named pipes</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_23">8 Communication in Client-server system</a>
<ul>
<li>
<a href="#toc_24">8.1 sockets</a>
</li>
<li>
<a href="#toc_25">8.2 Remote procedure calls</a>
</li>
</ul>
</li>
</ul>


<p><strong>Process</strong> (进程) is a program in execution.</p>

<ul>
<li>the unit of work in a modern computing system</li>
</ul>

<h2 id="toc_0">1 Process concept</h2>

<h3 id="toc_1">1.1 The process</h3>

<p>The status of the <strong>current</strong> activity of a process is represented by the value of the <strong>program counter</strong> and the contents of the processor&#39;s <strong>registers</strong>.</p>

<p>A program by itself is not a process.</p>

<ul>
<li>A program is a <strong>passive</strong> entity, such as a file containing a list of instructions stored on disk</li>
<li>A process is an <strong>active</strong> entity, with a program counter specifying the next instruction to execute</li>
</ul>

<h3 id="toc_2">1.2 Process state 进程状态</h3>

<p>A process may be in one of the following states:</p>

<ul>
<li><strong>New</strong>(新建). The process is being created. 进程正在被创建</li>
<li><strong>Running</strong>(运行). Instructions are being executed.指令正在被执行</li>
<li><strong>Waiting</strong>(等待). The process is waiting for some event to occur(such as an I/O completion or reception of a signal). 进程等待某些事件发生</li>
<li><strong>Ready</strong>(就绪). The process is waiting to be assigned to a processor.进程等待分配处理器</li>
<li><strong>Terminated</strong>(终止). The process has finished execution.进程执行完毕</li>
</ul>

<p>Diagram of process state:<br/>
<img src="media/15317585001692/diagramofprocessstate.png" alt="Diagram of process state"/></p>

<h3 id="toc_3">1.3 Process control block</h3>

<p>Each process is represented by a <strong>process control block</strong>(PCB, 进程控制块), it contains</p>

<ul>
<li><strong>Process state</strong>(进程状态)</li>
<li><strong>Program counter</strong>(程序计数器)</li>
<li><strong>CPU registers</strong>(CPU寄存器)</li>
<li><strong>CPU-scheduling information</strong>(CPU调度信息): a process priority, pointers to scheduling queues, and any other scheduling parameters.</li>
<li><strong>Memory-management information</strong>(内存管理信息)</li>
<li><strong>Accounting information</strong>(记账信息): the amount of CPU and real time used, time limits, account numbers, process numbers and so on.</li>
<li><strong>I/O status information</strong>(I/O状态信息): the list of I/O devices allocated to the process, a list of open files</li>
</ul>

<p>Process Control Block:<br/>
<img src="media/15317585001692/processcontrolblock.png" alt="process control block"/></p>

<p>The process control block in Linux is represented by the C structure <code>task_struct</code> (&#39;include/linux/sched.h&#39;)， <a href="https://elixir.bootlin.com/linux/latest/source/include/linux/sched.h#L592">CODE LINK</a></p>

<ul>
<li>Within the Linux kernel, all active processes are represented using a <strong>doubly linked list</strong> of task struct.</li>
</ul>

<p>Task_strut:<br/>
<img src="media/15317585001692/task_strcut%20in%20Linux.png" alt="task_strcut in Linux"/></p>

<h2 id="toc_4">2 Process scheduling 进程调度</h2>

<p>The <strong>process scheduler</strong>(进程调度程序) selects an available process for program execution on a core.</p>

<ul>
<li>Each CPU core can run one process at a time.</li>
<li>The number of processes currently in memory is known as the <strong>degree of multiprogramming</strong>.</li>
</ul>

<h3 id="toc_5">2.1 Scheduling Queues</h3>

<p><strong>Ready queue</strong>(就绪队列): the status of processes are ready.</p>

<ul>
<li>generally stored as a linked list, its header contains pointers to the first PCB in the list, each PCB includes a pointer field that points to next PCB in the ready queue.</li>
</ul>

<p><strong>Wait Queue</strong>(等待队列): the status of processes are waiting.</p>

<p>Queueing-diagram representation of process scheduling: <br/>
<img src="media/15317585001692/Queueing-diagram%20representation%20of%20process%20scheduling.png" alt="Queueing-diagram representation of process scheduling"/></p>

<h3 id="toc_6">2.2 context switch</h3>

<p>Here the <strong><em>context</em></strong> of a process is represented in the PCB of the process, including the value of the CPU registers, the process state, and memory-management information.</p>

<p>An operating system performs a <strong>context switch</strong>（上下文切换) when it switches from running one process to running another.</p>

<ul>
<li>The kernel <strong>saves</strong> the context of the old process into its PCB and <strong>restore</strong> the saved context of the new process scheduled to run.</li>
<li>Context-switch time is overhead; the system does no useful work while switching. 
<ul>
<li>A typical speed is a several microseconds. </li>
</ul></li>
<li>Context-switch times are <strong>highly</strong> dependent on hardware support.</li>
</ul>

<p>Context switch from an old process to a new process:<br/>
<img src="media/15317585001692/context%20switch%20from%20process%20to%20process.png" alt="context switch from process to process"/></p>

<h2 id="toc_7">3 Operating on Processes</h2>

<h3 id="toc_8">3.1 Process creation</h3>

<p>A process may <strong>create</strong> several new processes.</p>

<ul>
<li>the creating process is called a <strong>parent process</strong>.</li>
<li>the new process is called a <strong>child process</strong> .</li>
</ul>

<p><img src="media/15317585001692/process%20creating%20using%20the%20fork--%20system%20call.png" alt="process creating using the fork-- system cal"/></p>

<h3 id="toc_9">3.2 Process termintation</h3>

<p>A process <strong>terminates</strong> when it finishes executing its final statement and asks the operating system to delete it by using the <code>exit()</code> system call.</p>

<ul>
<li><strong>cascading termination</strong>(级联终止):  if a process terminates (either normally or abnormally), then all its children must also be terminated. </li>
<li>A process that has terminated, but whose parent has not yet called <code>wait()</code>, is known as a <strong>zombie process</strong>(僵尸进程).</li>
<li>if a parent did not invoke <code>wait()</code> and instead terminated, then leaving its child processes as <strong>orphan processes</strong>(孤儿进程).
<ul>
<li>Unix system may assign the <code>init</code> process as the new parent to orphan processes, and the <code>init</code> process periodically invokes <code>wait()</code>.</li>
</ul></li>
</ul>

<h2 id="toc_10">4 Interprocess communication</h2>

<p>Processes may be either <strong>independent processes</strong>(独立进程) or <strong>cooperating processes</strong>(协同进程).</p>

<ul>
<li>A process is <strong><em>independent</em></strong> if it does not share data with any other processes executing in the system.</li>
<li>A process is <strong><em>cooperating</em></strong> if it can affect or be affected by the other processes executing in the system.</li>
</ul>

<p>Advantages of  process cooperation:</p>

<ul>
<li>Information sharing 信息共享</li>
<li>Computation speedup 加速运算</li>
<li>Modularity 模块化</li>
</ul>

<p>Cooperating process require an <strong>interprocess communication</strong> (IPC，进程间通信) mechanism that will allow them to <strong>exchange</strong> data. There are two fundamental models of IPC:</p>

<ul>
<li><strong>shared memory</strong>（共享内存）: a region of memory is shared by cooperating process. Process can exchange information by reading and writing data to the shared region.
<ul>
<li>Shared memory can be <strong>faster</strong> than message passing.</li>
</ul></li>
<li><strong>message passing</strong>(消息传递)： communication takes place by means of messages exchanged between the cooperating processes.
<ul>
<li>Message passing is useful for exchanging <strong>smaller</strong> amounts of data, because no conflicts need be avoided.</li>
<li>Message passing is easier to implement in a distributed system than shared memory.</li>
</ul></li>
</ul>

<p><img src="media/15317585001692/sharedmemory%20and%20message%20passing.png" alt="sharedmemory and message passing"/></p>

<h2 id="toc_11">5 IPC in shared-memory system</h2>

<p>Here, we explore the POSIX API for shared memory. POSIX shared memory is organized using <strong>memory-mapped files</strong> (内存映射文件), which associate the region of shared memory with a file. A process must first create a shared-memory object using the <code>shm_open()</code> system call, as follows:</p>

<pre><code class="language-c">fd = shm_open(name, O_CREAT | O_RDWR, 0666);
ftruncate(fd, 4096);
mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
</code></pre>

<ul>
<li>A successful call to <code>shm_open()</code> returns an integer file descriptor for the shared-memory object.</li>
<li>Once the object is established, the <code>ftruncate</code> function is used to configure the size of the object in bytes.</li>
<li>Finally, the <code>mmap()</code> function establishes a memory-mapped file containing the shared-memory object. It returns a pointer to the shared</li>
</ul>

<h2 id="toc_12">6 IPC in message-passing system</h2>

<p>A message-passing facility provides at least two operations:</p>

<ul>
<li>send(message)</li>
<li>receive(message)</li>
</ul>

<p>If P and Q wish to communicate, they need to</p>

<ul>
<li>establish a <strong>communication link</strong>(通信连接) between them</li>
<li>exchange messages via send/receive </li>
</ul>

<p>Here are several methods for logically implementing a <em>communication link</em> between processes:</p>

<ul>
<li>Direct or indirect communication 直接/间接通信</li>
<li>Synchronous or asynchronous communication 同步/异步同步</li>
<li>Automatic or explicit buffering 自动/显式缓冲</li>
</ul>

<h3 id="toc_13">6.1 Direct/Indirect communication</h3>

<h4 id="toc_14">(1) Direct Communication</h4>

<p>Under <strong>direct communication</strong>, each process that wants to communicate must explicitly name the recipient or sender of the communication.</p>

<ul>
<li>send(P, message) - send a message to process P.</li>
<li>receive(Q, message) - receive a message from process Q</li>
</ul>

<p>A communication link in this scheme has the following properties:</p>

<ul>
<li>A link is established <strong>automatically</strong> between every pair of processes that want to communicate.</li>
<li>A link is associated with <strong>exactly two</strong> processes.</li>
<li>Between each pair of processes, there exists exactly one link.</li>
</ul>

<p>Cons:</p>

<ul>
<li>limited modularity of the resulting process definitions. Changing the identifier of a process may necessiate examining all other process definitions.</li>
<li>any such hard-coding techniques, are less desirable.</li>
</ul>

<h4 id="toc_15">(2) Indirect Communication**</h4>

<p>With <strong>indirect communication</strong>, the message are sent to and receive from <strong>mailboxes</strong>, or <strong>ports</strong>.</p>

<ul>
<li>send(A, message) - send a message to mailbox A</li>
<li>receive(A, message) - receive a message from mailbox A</li>
</ul>

<p>A mailbox can be viewed abstractly as an object into which messages can be placed by processes and from which messages can be removed.</p>

<ul>
<li>Each mailbox has an <strong>unique</strong> identification.</li>
<li>Two processes can communicate only if they have a shared mailbox.</li>
</ul>

<p>In this scheme, a communication link has the following properties:</p>

<ul>
<li>A link is established between a pair of processes only if both members of the pair have a shared mailbox.</li>
<li>A link may be associated with more than two processes.</li>
<li>Between each pair of communicating processes, a number of different links may exist, with each link corresponding to one mailbox.</li>
</ul>

<p>A mailbox may be owned either by a process or by the operating system.</p>

<p>If the mailbox is owned by a process</p>

<ul>
<li>We distinguish between the <strong>owner</strong> (which can only receive messages through his mailbox) and the <strong>user</strong> (which can only send messages to the mailbox)</li>
<li>Each mailbox has a unique owner.</li>
<li>When a process that owns a mailbox terminates, the mailbox disappears.</li>
<li>The process that creates a new mailbox is that mailbox&#39;s owner by default.</li>
</ul>

<h3 id="toc_16">6.2 Synchronization</h3>

<p>Message passing may be either <strong>blocking</strong> or <strong>nonblocking</strong> - also known as <strong>synchronous</strong> and <strong>asynchronous</strong>.</p>

<h3 id="toc_17">6.3 Buffering</h3>

<p>Messages exchanged by communicating processes reside in a temporary queue, whether communication is direct or indirect. Basically, it can be implemented in three ways:</p>

<ul>
<li>Zero capacity（零容量）-- no buffering
<ul>
<li>The link cannot have any messages waiting in it.</li>
<li>The sender must block until the recipient receives the message. </li>
</ul></li>
<li>Bounded capacity（有界容量）-- automatic buffering
<ul>
<li>The queue has finite length n, at most n message can reside in it.<br/></li>
<li>The sender must block until space is available in the queue if the link is full.<br/></li>
</ul></li>
<li>Unbounded capacity （无界容量） -- automatic buffering
<ul>
<li>Any number of messages can wait in it.</li>
<li>The sender never blocks. </li>
</ul></li>
</ul>

<h2 id="toc_18">7 Examples of IPC</h2>

<h3 id="toc_19">7.1 Mach Message Passing</h3>

<p>Mach was especially designed for distributed systems. Its kernel supports the creation and destruction of multiple <strong>tasks</strong>, which are similar to processes but have multiple threads of control and fewer associated resources.  </p>

<p>Messages are sent to, and received from, mailboxes, which are called <strong>ports</strong> in Mach. </p>

<ul>
<li>Ports are finite in size and unidirectional.</li>
<li>for two-way communication, a message is sent to one port, and a response is sent to a separate <strong>reply</strong> port.</li>
<li>Associated with each port is a collection of <strong>port rights</strong>, which  identify the capabilities necessary for a task to interact with the port.</li>
</ul>

<p>Functions:</p>

<ul>
<li><code>mach_port_allocate()</code> creates a new port and allocates space for its queue of messages.</li>
<li><code>mach_msg()</code> is the standard API for both sending and receiving messages.</li>
</ul>

<pre><code class="language-c">#include &lt;mach/mach.h&gt;

struct message {
    mach_msg_header_t header;
    int data;
};

mach_port_t client;
mach_port_t server;

/* Client Code */

struct message message;

// construct the header
message.header.msgh_size = sizeof(message);
message.header.msgh_remote_port = server;
message.header.msgh_local_port = client;

// send the message
mach msg(&amp;message.header, // message header
         MACH_SEND_MSG, // sending a message
         sizeof(message), // size of message sent
         0, // maximum size of received message - unnecessary
         MACH_PORT_NULL, // name of receive port - unnecessary
         MACH_MSG_TIMEOUT_NONE, // no time outs MACH PORT NULL // no notify port
);

/* Server Code */

struct message message;

// receive the message
mach_msg(&amp;message.header, // message header
  MACH_RCV_MSG, // sending a message  0, // size of message sent
  sizeof(message), // maximum size of received message
  server, // name of receive port
  MACH_MSG_TIMEOUT_NONE, // no time outs
  MACH_PORT_NULL // no notify port
);
</code></pre>

<h3 id="toc_20">7.2 Pipes</h3>

<p>A <strong>pipe</strong> acts as a conduit allowing two processes to communicate. There are two common types of pipes used on both UNIX and Windows systems: <strong>ordinary pipes</strong> and <strong>named pipes</strong>.</p>

<h4 id="toc_21">(1) Ordinary pipes</h4>

<p><strong>Ordinary pipes</strong> allow two processes to communicate in standard producer-consumer fashion: the producer writes to one end of the pipe (the <strong>write end</strong>) and the consumer reads from the other end (the <strong>read end</strong>).</p>

<ul>
<li>Ordinary pipes are <strong>unidirectional</strong>, allowing only one-way communication.</li>
<li>Function <code>pipe(int fd[])</code> constructs an ordinary pipe, where <code>fd</code> is a file descriptor.</li>
<li>UNIX treats a pipe as <em>a special type of file</em>. Pipes can be accessed using ordinary <code>read()</code> and <code>write()</code> system calls.</li>
<li>Ordinary pipes <strong>exit only</strong> while the processes are communicating with each other.</li>
</ul>

<p><img src="media/15317585001692/file%20descriptors%20for%20an%20ordinary%20pipes.png" alt="file descriptors for an ordinary pipes"/></p>

<pre><code class="language-c">#include &lt;sys/types.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;unistd.h&gt;

#define BUFFER_SIZE 25
#define READ_END 0
#define WRITE_END 1

int main(void)
{
        char write_msg[BUFFER_SIZE] = &quot;Greetings&quot;;
        char read_msg[BUFFER_SIZE];
        int fd[2];
        pid_t pid;

        /* create the pipe */
        if (pipe(fd) == -1){
                fprintf(stderr, &quot;Pipe failed&quot;);
                return 1;
        }

        /* fork a child process */
        pid = fork();

        if (pid&gt;0){ /* parent process */
                close(fd[READ_END]);/* close the unused end of the pipe */
                write(fd[WRITE_END], write_msg, strlen(write_msg)+1); /* write to the pipe */
                close(fd[WRITE_END]);  /* close the write end of the pipe */
        }
        else if (pid==0){ /* child process */
                close(fd[WRITE_END]); /* close the unused end of the pipe */
                read(fd[READ_END], read_msg, BUFFER_SIZE); /* read from the pipe */
                printf(&quot;read: %s\n&quot;, read_msg);
                close(fd[READ_END]); /* close the read end of the pipe */
        }
        return 0;

}
</code></pre>

<h4 id="toc_22">(2) Named pipes</h4>

<p><strong>Named pipes</strong>（命名管道） can be bidirectional, and no parent-child relationship is required.</p>

<ul>
<li>Named pipes are referred to as FIFOs in UNIX system.</li>
<li>The communicating processes for named pipes must reside on the same machine.</li>
</ul>

<p>创建命名管道：</p>

<pre><code class="language-c">int mkfifo(const char *filename, mode_t mode);
</code></pre>

<h2 id="toc_23">8 Communication in Client-server system</h2>

<p>In this section, we explore two other strategies for communication in client-server system: <strong>sockets</strong> and <strong>remote procedure calls</strong>(RPCs)</p>

<h3 id="toc_24">8.1 sockets</h3>

<p>A socket（套接字）is defined as an endpoint for communication. A socket is identified by an IP address concatenated with a port number.</p>

<p>Communication using sockets<br/>
<img src="media/15317585001692/communication%20using%20sockets.png" alt="communication using sockets"/></p>

<h3 id="toc_25">8.2 Remote procedure calls</h3>

<p><strong>Remote Procedure Call</strong>（远程过程调用）allows programs on different machines to interact using simple procedure call/return semantics, just as if the two programs were in the same computer。</p>

<p>RPC between a client and a serve：<br/>
<img src="media/15317585001692/RPC%20between%20a%20client%20and%20a%20server.png" alt="RPC between a client and a serve"/></p>

<p>RPC hides all the network code into the stub procedures. This prevents the application programs, the client and the server, from having to worry about details such as sockets, network byte order, and the like.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Operating System Concepts 1 - Introduction]]></title>
    <link href="http://larryim.cc/os-concepts-introduction.html"/>
    <updated>2018-07-16T18:07:17+08:00</updated>
    <id>http://larryim.cc/os-concepts-introduction.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">what operating system do</a>
</li>
<li>
<a href="#toc_1">Computer-system organisation</a>
</li>
<li>
<a href="#toc_2">Interrupt</a>
<ul>
<li>
<a href="#toc_3">interrupt, exception, trap</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">multiprogramming and multitasking</a>
</li>
<li>
<a href="#toc_5">dual-mode</a>
</li>
<li>
<a href="#toc_6">timer</a>
</li>
<li>
<a href="#toc_7">virtualization</a>
</li>
<li>
<a href="#toc_8">Free and Open-Source OS</a>
</li>
</ul>


<h2 id="toc_0">what operating system do</h2>

<p>There is no completely adequate definition of operating system. A simple viewpoint is that it includes everything a vendor ships. A more common definition is that the <u>operating system is the one program running at all times on computer - usually  called <strong>kernel</strong></u> . </p>

<p>Three main <strong>purposes</strong> of an operating system are,</p>

<ul>
<li>manages a computer&#39;s hardware</li>
<li>provides a basis for application programs</li>
<li>acts as an intermediary between the user and hardware</li>
</ul>

<p>The operating system includes the always running <strong>kernel</strong>, <strong>middleware</strong> frameworks that ease application development and provide features, and <strong>system programs</strong> that aid in managing the system while it is running.</p>

<p>Anything between the kernel and user applications is considered <strong>middleware</strong>(中间件) [<a href="https://en.wikipedia.org/wiki/Middleware">1</a>].</p>

<h2 id="toc_1">Computer-system organisation</h2>

<p>A computer system can be divided roughly into four components: the <strong>hardware</strong>, the <strong>operating system</strong>, the <strong>application programs</strong>, and a <strong>user</strong>.</p>

<p><img src="http://or9a8nskt.bkt.clouddn.com/abstractviewofcomputersytem.png" alt="Abstract view of the components of a computer system"/></p>

<p>A <strong>computer system</strong>(计算机系统) consists of one or more <strong>CPUs</strong> and a number of <strong>device controllers</strong>(设备控制器) connected through a common <strong>bus</strong>(总线) that provides access between components and shared <strong>memory</strong>.</p>

<p>A <strong>device controller</strong> maintains some <strong>local buffer storage</strong>(局部缓冲存储) and a set of special-purpose <strong>registers</strong>.</p>

<hr/>

<p>Typically, operating systems have a <strong>device driver</strong>(设备驱动) for each device controller. This device driver understands the device controller and provides the rest of the operating system with a uniform interface to the device</p>

<p><img src="http://or9a8nskt.bkt.clouddn.com/AtypicalPCcomputerSystem.png" alt="一个典型的PC计算机系统"/></p>

<h2 id="toc_2">Interrupt</h2>

<p>When the CPU is <strong>interrupted</strong>, it stops what it is doing and immediately transfers execution to a fixed location. The fixed location usually contains the starting address where the service routine for the interrupt is located.</p>

<p>The <strong>interrupt routine</strong>(中断程序) is called indirectly through the interrupt vector table（中断向量表).</p>

<ul>
<li>Generally, the table of pointers is stored in low memory (the first hundred or so locations).</li>
<li>These locations hold the addresses of the interrupt service routines for the various devices.</li>
<li>Interrupt vector is then indexed by a unique number(interrupt vector number, 中断向量号)</li>
<li>interrupt priority levels(中断优先级)</li>
</ul>

<p><img src="http://or9a8nskt.bkt.clouddn.com/interruptvectortable.png" alt="中断向量号"/></p>

<p>Some <strong>services</strong> are provided outside of the kernel by system programs that are loaded into memory at boot time to become system <strong>daemons</strong>, which run the entire time the kernel is running.</p>

<p><img src="http://or9a8nskt.bkt.clouddn.com/interrupt-driven%20I:O%20cycle.png" alt="interrupt-driven I:O cycle"/></p>

<h3 id="toc_3">interrupt, exception, trap</h3>

<p>Unfortunately, there is no clear consensus as to the exact meaning of these terms(exceptions, faults, aborts, traps, and interrupts). Different authors adopt different terms to their own use [<a href="http://www.plantation-productions.com/Webster/www.artofasm.com/DOS/pdf/ch17.pdf">ref</a>].</p>

<p><strong>trap</strong>(陷阱) or <strong>exception</strong>(异常): a software-generated interrupt either by an error（e.g. division by zero, or invalid memory access or by a system call.</p>

<ul>
<li>usual way to invoke a kernel routine (a system call) </li>
</ul>

<p><strong>interrupt</strong>(中断):  generated by the hardware (devices like the hard disk, graphics card, I/O ports, etc).</p>

<h2 id="toc_4">multiprogramming and multitasking</h2>

<p><strong>Multiprogramming</strong>(多道程序) explained:</p>

<ul>
<li>The operating system <strong>keeps several processes in memory</strong> simultaneously. </li>
<li>The operating system picks and begins to execute one of these processes.</li>
<li>Eventually, the process may have to wait for some task, such as an I/O operation, to complete.</li>
<li>When that process needs to wait, the CPU <strong>switches</strong> to another process, and so on.</li>
<li> Eventually, the first process finishes waiting and gets the CPU back. As long as at least one process needs to execute, the <strong>CPU is never idle</strong>.</li>
</ul>

<p><strong>Multitasking</strong>(多任务) is a logical <strong>extension</strong> of multiprogramming. In multitasking systems, the CPU executes multiple processes by switching among them, but the switches occur <strong>frequently</strong>, providing the user with a <strong>fast</strong> response time.</p>

<h2 id="toc_5">dual-mode</h2>

<p>In order to ensure the proper execution of the system, we must be able to distinguish between the execution of operating-system code（<strong>kernel mode</strong>）and user-defined code (<strong>user mode</strong>).</p>

<p><img src="http://or9a8nskt.bkt.clouddn.com/transitionfromusermodetokernelmode.png" alt="Transition from user mode to kernel mode"/></p>

<p><strong>Mode bit</strong>(模式位), is added to the hardware of the computer to indicate the current mode: kernel (0) or user (1).</p>

<p>The concept of modes can be <strong>extended</strong> beyond two modes. </p>

<ul>
<li><p><strong>protection rings</strong>（保护环) are mechanisms to protect data and functionality from faults (by improving fault tolerance) and malicious behavior (by providing computer security). </p></li>
<li><p>For intel processors, ring 0 is kernel mode and ring 3 is user mode</p></li>
</ul>

<p><img src="http://or9a8nskt.bkt.clouddn.com/15317318589869.jpg" alt=""/></p>

<h2 id="toc_6">timer</h2>

<p>A timer (定时器) can  be set to interrupt the computer after a specified period( usually, 100s hz)</p>

<ul>
<li>A variable timer is generally implemented by a fixed-rate clock and a counter. </li>
<li>The operating system sets the counter. Every time the clock ticks, the counter is decremented. </li>
<li>When the counter reaches 0, an interrupt occurs.</li>
</ul>

<h2 id="toc_7">virtualization</h2>

<p><strong>virtualization</strong>(虚拟化) is a technology that allows us to abstract the hardware of a single computer into several different execution environments, thereby creating the illusion that <u><em>each separate environment is running on its own private computer</em></u> .</p>

<ul>
<li>v.s. [different] Emulation involves simulating computer handware in software.</li>
</ul>

<p><img src="http://or9a8nskt.bkt.clouddn.com/virtualmachines.png" alt="A computer running (a) a single operating system and (b) three virtual machines"/></p>

<h2 id="toc_8">Free and Open-Source OS</h2>

<p>Open-source OS</p>

<ul>
<li>source code available</li>
<li>opposite: closed-source OS</li>
</ul>

<p>Free OS</p>

<ul>
<li>source code available</li>
<li>allow no-cost use, redistribution, and modification</li>
</ul>

<p>Arguably, open-source code is <strong>more secure</strong> than closed-source code because many more eyes are viewing the code.</p>

<p>e.g. OS</p>

<ul>
<li> GNU/Linux</li>
<li> FreeBSD</li>
<li> Solaris</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Operating System Concepts 2 - Operating System structures]]></title>
    <link href="http://larryim.cc/os-concepts-os-structures.html"/>
    <updated>2018-07-16T18:16:02+08:00</updated>
    <id>http://larryim.cc/os-concepts-os-structures.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">Operating system service</a>
</li>
<li>
<a href="#toc_1">User Interface</a>
</li>
<li>
<a href="#toc_2">System call</a>
<ul>
<li>
<a href="#toc_3">API</a>
</li>
<li>
<a href="#toc_4">Types of system calls</a>
</li>
</ul>
</li>
<li>
<a href="#toc_5">System Service</a>
</li>
<li>
<a href="#toc_6">OS Design and Implementation</a>
</li>
<li>
<a href="#toc_7">Operating system structure</a>
<ul>
<li>
<a href="#toc_8">Monolithic structure</a>
</li>
<li>
<a href="#toc_9">Layered</a>
</li>
<li>
<a href="#toc_10">Microkernel</a>
</li>
<li>
<a href="#toc_11">Modules</a>
</li>
<li>
<a href="#toc_12">Hybrid systems</a>
</li>
</ul>
</li>
<li>
<a href="#toc_13">System boot</a>
</li>
</ul>


<h2 id="toc_0">Operating system service</h2>

<p>The figure below is a view of the various operating-system services and how they interrelate.</p>

<p><img src="media/15317361625058/A%20view%20of%20operating%20system%20services.png" alt="A view of operating system services"/></p>

<h2 id="toc_1">User Interface</h2>

<p>There&#39;re mainly three ways for users to interface with the operating system:</p>

<ul>
<li>command interpreter</li>
<li>graphical user interface</li>
<li>touch-screen interface</li>
</ul>

<h2 id="toc_2">System call</h2>

<p>Purpose of System Call: System calls provide an <strong>interface to the services</strong> made available by an operating system.</p>

<h3 id="toc_3">API</h3>

<p>Typically, application developers design programs according to an application programming interface(<strong>API</strong>, 应用程序编程接口) rather than invoking <strong>actual system call</strong>.</p>

<ul>
<li>because even simple program may make heavy use of system call.</li>
<li><strong>program portabilit</strong>y: expect programs to compile and run other system that supports the same API</li>
<li><strong>run-time environment</strong>(RTE, 运行时环境) - the full suit of software needed to execute applications, including its compilers, interpreters, libraries, loaders.</li>
</ul>

<h3 id="toc_4">Types of system calls</h3>

<p>System calls can be grouped roughly into six major categories:<br/>
系统调用可分成六大类：进程控制，文件管理，设备管理，信息维护，通信和保护。</p>

<ul>
<li>process control</li>
<li>file management</li>
<li>device management</li>
<li>information maintenance</li>
<li>communications</li>
<li>protection</li>
</ul>

<p><img src="media/15317361625058/examplesofunixandlinuxsystemcalls.png" alt="Examples of Windows and Unix systemcalls"/></p>

<p>Three ways to pass parameters to the operating system:</p>

<ul>
<li>when less than five parameters, passing the parameters in registers</li>
<li>when more than five parameters, parameters are stored in a block, passing the address of the block in a register</li>
<li>using stack</li>
</ul>

<h2 id="toc_5">System Service</h2>

<p><strong>System services</strong>, also known as <strong>system utilities</strong>, provide a convenient environment for program development and execution.</p>

<h2 id="toc_6">OS Design and Implementation</h2>

<p>One important principle of OS design is <u>the separation of <strong>policy</strong> from <strong>mechanism</strong></u> . Mechanisms determine <strong>how</strong> to do something; policies determine <strong>what</strong> will be done.<br/>
操作系统设计的一个重要原则是策略（policy）和机制（mechanism）的分离。机制决定如何做，策略决定做什么。</p>

<ul>
<li>The separation of policy and mechanism is important for <strong>flexibility</strong>.</li>
</ul>

<h2 id="toc_7">Operating system structure</h2>

<h3 id="toc_8">Monolithic structure</h3>

<p>Operating systems with <strong>monolithic structure</strong> (单体结构) place all of the functionality of kernel into a <strong>single</strong>, <strong>static</strong> binary file that runs in a <strong>single</strong> address space.</p>

<ul>
<li>a common technique for designing operating system</li>
<li>e.g. original Unix operating system ( figure below)</li>
</ul>

<p><img src="media/15317361625058/traditional%20unix%20system%20structure.png" alt="Traditional Unix system structure"/></p>

<ul>
<li>e.g. Linux is based on Unix and is structured similarly, as shown in figure below.</li>
</ul>

<p><img src="media/15317361625058/linux%20system%20structure.png" alt="linux system structure"/></p>

<p>pros</p>

<ul>
<li>simplicity of kernels</li>
<li>a distinct performance advantage</li>
<li>very little overhead in the system-call interface</li>
<li>fast communication within the kernel</li>
</ul>

<p>cons</p>

<ul>
<li>difficult to implement and extend</li>
</ul>

<h3 id="toc_9">Layered</h3>

<p>A <strong>loosely coupled</strong> (松耦合) system is divided into separate, smaller components that have specific and limited functionality (<strong>modular</strong> approach). All these components together comprise the kernel .</p>

<ul>
<li>changes in one component affect only that component</li>
</ul>

<p>A system can be made modular in many ways.</p>

<ul>
<li>one way is the layered approach.</li>
</ul>

<p>For the <strong>layered operating system</strong> (层次式操作系统), it is broken into a number of layers.</p>

<ul>
<li>The bottom layer is the hardware; the highest is the user interface.</li>
<li>low-level layers can be invoked by higher-level layers</li>
</ul>

<p>pros</p>

<ul>
<li>simplicity of construction and debugging
<ul>
<li>each layer is implemented only with operations provided by lower-level layers. </li>
<li>higher-level layers can be debugged without any concern for the lower-level layers</li>
</ul></li>
</ul>

<p>cons</p>

<ul>
<li>difficulty of defining the functionality of each layer</li>
<li>poor performance
<ul>
<li>overhead of requiring a user program to traverse through multiple layers to obtain an operating-system service </li>
</ul></li>
</ul>

<p>Used in computer networks and web applications</p>

<p><img src="media/15317361625058/alayeredoperatingsystem.png" alt="A layered operating system"/></p>

<h3 id="toc_10">Microkernel</h3>

<p>Another way to modularized the kernel is using microkernel approach (微内核)。</p>

<ul>
<li><strong>removing all nonessential</strong> components from the kernel and implementing them as <strong>user-level</strong> programs the reside in <strong>separate</strong> address spaces.</li>
<li>smaller kernel</li>
</ul>

<p>A typical microkernel shown below.<br/>
<img src="media/15317361625058/a%20typical%20microkernel.png" alt="A typical microkernel"/></p>

<p>pros</p>

<ul>
<li>easy to extend the os
<ul>
<li>all new services added to user space do not require modification of the kernel.</li>
<li>when modification of kernel needed, changes tend to be fewer because of small kernel</li>
</ul></li>
<li>more security and reliability
<ul>
<li>since most services are running as user</li>
</ul></li>
</ul>

<p>cons</p>

<ul>
<li>performance may suffer due to increased system function overhead.
<ul>
<li>messages of user-level services to communicate must be copied between the services. </li>
</ul></li>
</ul>

<p>Best-known microkernel os is <strong>Darwin</strong>, the kernel component of the macOS and iOS.  </p>

<h3 id="toc_11">Modules</h3>

<p>Perhaps the best current methodology for operating system design involves using <strong>loadable kernel modules</strong>(LVMs, 可装载内核模块). Here, the kernel has a set of core components and can link in additional services via modules, either at boot time or during run time.</p>

<ul>
<li>design purpose: for the kernel to provide core services, while other services are implemented <strong>dynamically</strong>, as the kernel is running</li>
</ul>

<h3 id="toc_12">Hybrid systems</h3>

<p>In practice, <strong>very few</strong> operating system adopt a single, strictly defined structure. Instead, they <strong>combine different structures</strong><br/>
, resulting in <strong>hybrid systems</strong> that address performance, security, and usability issues.</p>

<p>Architecture of Apple’s macOS and iOS operating systems:<br/>
<img src="media/15317361625058/Architecture%20of%20Apple%E2%80%99s%20macOS%20and%20iOS%20operating%20systems.png" alt="Architecture of Apple’s macOS and iOS operating systems"/></p>

<p>Darwin provides two system-call interfaces: Mach system calls and BSD system calls.</p>

<p>The structure of Darwin:<br/>
<img src="media/15317361625058/The%20structure%20of%20Darwin..png" alt="The structure of Darwin."/></p>

<p>To address such performance problems, Darwin combines Mach, BSD, the I/O kit, and any kernel extensions into a <strong>single</strong> address space.</p>

<p><a href="https://developer.apple.com/library/archive/documentation/Darwin/Conceptual/KernelProgramming/Architecture/Architecture.html#//apple_ref/doc/uid/TP30000905-CH1g-CACDAEDC">detailed documents for Darwin kernel</a></p>

<h2 id="toc_13">System boot</h2>

<p>The process of starting a computer by loading the kernel is known as <strong>booting</strong> the system.</p>

<ol>
<li>A small piece of code known as the <strong>bootstrap program</strong>（引导程序） or boot loader locates the kernel.</li>
<li>The kernel is loaded into memory and started.</li>
<li>The kernel initializes hardware.</li>
<li>The root file system is mounted.</li>
</ol>

<p>bootstrap program:</p>

<ul>
<li>usually, bootstrap program located in BIOS( nonvolatile firmware(固件) on motherboard, <a href="https://en.wikipedia.org/wiki/BIOS">wiki</a>)</li>
<li><strong>GRUB</strong> is an open-source bootstrap program for Linux and Unix systems <a href="https://en.wikipedia.org/wiki/GNU_GRUB">wiki</a>.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Operating System - History]]></title>
    <link href="http://larryim.cc/15317613286610.html"/>
    <updated>2018-07-17T01:15:28+08:00</updated>
    <id>http://larryim.cc/15317613286610.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">reference</h2>

<ul>
<li>modern operating system 4th</li>
<li>operating system concepts 10th</li>
<li>图解TCP/IP协议</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop the definitive guide 1 - Hadoop fundamentals]]></title>
    <link href="http://larryim.cc/Hadoop%20_the_definitive_guide_1-Hadoop_fundamentals.html"/>
    <updated>2018-07-17T00:56:20+08:00</updated>
    <id>http://larryim.cc/Hadoop%20_the_definitive_guide_1-Hadoop_fundamentals.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - 链接]]></title>
    <link href="http://larryim.cc/Linking.html"/>
    <updated>2018-01-06T05:42:41+08:00</updated>
    <id>http://larryim.cc/Linking.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">1 编译器驱动程序</a>
</li>
<li>
<a href="#toc_1">2 静态链接</a>
</li>
<li>
<a href="#toc_2">3 目标文件</a>
</li>
<li>
<a href="#toc_3">4 可重定位目标文件</a>
</li>
<li>
<a href="#toc_4">5 符号和符号表</a>
</li>
<li>
<a href="#toc_5">6 符号解析</a>
</li>
<li>
<a href="#toc_6">7 重定位</a>
</li>
<li>
<a href="#toc_7">8 可执行目标文件</a>
</li>
<li>
<a href="#toc_8">9 加载可执行目标文件</a>
</li>
<li>
<a href="#toc_9">10 动态链接共享库</a>
</li>
<li>
<a href="#toc_10">14 处理目标文件的工具</a>
</li>
</ul>


<p><strong>链接</strong>(Linking)是将各种<strong>代码</strong>和<strong>数据片段</strong>收集并组合成为一个单一文件的过程。链接可以在编译、加载、运行时执行。在现代系统中，链接由<strong>链接器</strong>(Linker)自动执行。</p>

<p>链接器使得<strong>分离编译</strong>(separate compilation)成为可能：</p>

<ul>
<li>可以将源文件分解为更小、更好管理的模块，可以独立地修改和编译这些模块</li>
<li>修改一个模块后，只需重新编译它，并重新链接，不必编译其他文件</li>
</ul>

<h2 id="toc_0">1 编译器驱动程序</h2>

<p><strong>编译器驱动程序</strong>(<code>compiler driver</code>)，代表用户在需要时调用预处理器(cpp)、编译器(ccl)、汇编器(as)和链接器(ld)。典型的编译器驱动程序，包括GNU GCC, Clang。</p>

<p>例如，一个简单打印hello的<code>hello.c</code>程序，经过下面四个阶段，生成可执行目标文件：</p>

<pre><code class="language-c">//file: hello.c
#include &lt;stdio.h&gt;

int main()
{
    int i;
    printf(&quot;Hello World&quot;);
}
</code></pre>

<pre><code class="language-bash">linux &gt; gcc -o hello hello.c
</code></pre>

<p><img src="media/15151885614329/compiler_system.jpeg" alt="compiler_syste"/></p>

<h2 id="toc_1">2 静态链接</h2>

<p>静态链接器有两个主要任务：</p>

<ul>
<li><strong>符号解析</strong>(symbol resolution): 将每个符号 <u>引用</u> 正好和一个符号 <u>定义</u> 关联起来。</li>
<li><strong>重定位</strong>(relocation): 把每个符号定义与一个内存位置关联起来，并修改所有对这些符号的引用，使得它们指向这个内存位置。</li>
</ul>

<h2 id="toc_2">3 目标文件</h2>

<p>目标文件有三种格式：<strong>可重定位目标文件</strong>(<code>.o</code>)，<strong>可执行目标文件</strong>(<code>.out</code>)，<strong>共享目标文件</strong>(<code>.so</code>)</p>

<ul>
<li><strong>可重定位目标文件</strong>(.o文件)。包含二进制代码和数据，其形式可以在编译时与其他可重定位目标文件合并起来，创建一个可执行目标文件。</li>
<li><strong>可执行目标文件</strong>(a.out文件)。包含二进制代码和数据，其形式可以被直接复制到内存并执行。</li>
<li><strong>共享目标文件</strong>(.so文件)。在加载或者运行时被动态地加载进内存并链接</li>
</ul>

<p>各个系统的目标文件格式不同，Windows使用<strong>可移植可执行</strong>(Portable Executable, <code>PE</code>)格式。现代x86-64系统使用<strong>可执行可链接格式</strong>(Executable and Linkable Format, <code>ELF</code>)。</p>

<h2 id="toc_3">4 可重定位目标文件</h2>

<p>以可执行可链接(ELF)格式为例，一个典型的可重定位目标文件包括以下几个节：</p>

<ul>
<li>ELF头和节头部表</li>
<li><code>.text</code> 已编译程序的机器代码</li>
<li><code>.rodata</code> 只读数据</li>
<li><code>.data</code>  已初始化的全局和静态C变量</li>
<li><code>.bss</code>  未初始化的全局和静态C变量</li>
<li><code>.symtab</code> 一个符号表</li>
<li><code>.rel.text</code> 一个.text节中位置的列表</li>
<li><code>.rel.data</code> 重定位信息</li>
<li><code>.debug</code> 调试符号表</li>
<li><code>.line</code>  原始程序行号和机器指令之间的映射</li>
<li><code>.strtab</code>  字符串表</li>
</ul>

<p><img src="media/15151885614329/elf.png" alt="elf"/></p>

<p>利用<code>READELF</code>程序可以显示程序<code>hello.c</code>生成的可执行可链接文件的信息：</p>

<pre><code class="language-bash">gcc hello.c -c
readelf -a hello.o
</code></pre>

<pre><code class="language-text">ELF Header:
  Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00
  Class:                             ELF64
  Data:                              2&#39;s complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              REL (Relocatable file)
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0x0
  Start of program headers:          0 (bytes into file)
  Start of section headers:          304 (bytes into file)
  Flags:                             0x0
  Size of this header:               64 (bytes)
  Size of program headers:           0 (bytes)
  Number of program headers:         0
  Size of section headers:           64 (bytes)
  Number of section headers:         13
  Section header string table index: 10

Section Headers:
  [Nr] Name              Type             Address           Offset
       Size              EntSize          Flags  Link  Info  Align
  [ 0]                   NULL             0000000000000000  00000000
       0000000000000000  0000000000000000           0     0     0
  [ 1] .text             PROGBITS         0000000000000000  00000040
       0000000000000015  0000000000000000  AX       0     0     1
  [ 2] .rela.text        RELA             0000000000000000  00000590
       0000000000000030  0000000000000018          11     1     8
  [ 3] .data             PROGBITS         0000000000000000  00000055
       0000000000000000  0000000000000000  WA       0     0     1
  [ 4] .bss              NOBITS           0000000000000000  00000055
       0000000000000000  0000000000000000  WA       0     0     1
  [ 5] .rodata           PROGBITS         0000000000000000  00000055
       000000000000000c  0000000000000000   A       0     0     1
  [ 6] .comment          PROGBITS         0000000000000000  00000061
       000000000000002c  0000000000000001  MS       0     0     1
  [ 7] .note.GNU-stack   PROGBITS         0000000000000000  0000008d
       0000000000000000  0000000000000000           0     0     1
  [ 8] .eh_frame         PROGBITS         0000000000000000  00000090
       0000000000000038  0000000000000000   A       0     0     8
  [ 9] .rela.eh_frame    RELA             0000000000000000  000005c0
       0000000000000018  0000000000000018          11     8     8
  [10] .shstrtab         STRTAB           0000000000000000  000000c8
       0000000000000061  0000000000000000           0     0     1
  [11] .symtab           SYMTAB           0000000000000000  00000470
       0000000000000108  0000000000000018          12     9     8
  [12] .strtab           STRTAB           0000000000000000  00000578
       0000000000000015  0000000000000000           0     0     1
Key to Flags:
  W (write), A (alloc), X (execute), M (merge), S (strings), l (large)
  I (info), L (link order), G (group), T (TLS), E (exclude), x (unknown)
  O (extra OS processing required) o (OS specific), p (processor specific)

There are no section groups in this file.

There are no program headers in this file.

Relocation section &#39;.rela.text&#39; at offset 0x590 contains 2 entries:
  Offset          Info           Type           Sym. Value    Sym. Name + Addend
000000000005  00050000000a R_X86_64_32       0000000000000000 .rodata + 0
00000000000f  000a00000002 R_X86_64_PC32     0000000000000000 printf - 4

Relocation section &#39;.rela.eh_frame&#39; at offset 0x5c0 contains 1 entries:
  Offset          Info           Type           Sym. Value    Sym. Name + Addend
000000000020  000200000002 R_X86_64_PC32     0000000000000000 .text + 0

The decoding of unwind sections for machine type Advanced Micro Devices X86-64 is not currently supported.

Symbol table &#39;.symtab&#39; contains 11 entries:
   Num:    Value          Size Type    Bind   Vis      Ndx Name
     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS hello.c
     2: 0000000000000000     0 SECTION LOCAL  DEFAULT    1
     3: 0000000000000000     0 SECTION LOCAL  DEFAULT    3
     4: 0000000000000000     0 SECTION LOCAL  DEFAULT    4
     5: 0000000000000000     0 SECTION LOCAL  DEFAULT    5
     6: 0000000000000000     0 SECTION LOCAL  DEFAULT    7
     7: 0000000000000000     0 SECTION LOCAL  DEFAULT    8
     8: 0000000000000000     0 SECTION LOCAL  DEFAULT    6
     9: 0000000000000000    21 FUNC    GLOBAL DEFAULT    1 main
    10: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND printf

No version information found in this file.
</code></pre>

<h2 id="toc_4">5 符号和符号表</h2>

<p><code>.symtab</code>中的<strong>符号表</strong>，有三种不同的符号(不包括本地非静态变量)：</p>

<ul>
<li>由模块\(m\)定义并能被其他模块引用的<strong>全局符号</strong>。
<ul>
<li>非静态C函数和全局变量</li>
</ul></li>
<li>由其他模块定义并被模块\(m\)引用的全局符号。
<ul>
<li>对应于其他模块中定义的非静态C函数和全局变量</li>
</ul></li>
<li>只被模块\(m\)定义和引用的局部符号。
<ul>
<li>静态C函数和全局变量 </li>
</ul></li>
</ul>

<h2 id="toc_5">6 符号解析</h2>

<p><strong>符号解析</strong>是将每个<strong>符号引用</strong>和可重定位目标文件中的<strong>符号定义</strong>关联起来。链接器的输入是一组可重定位目标文件(模块)，有些是局部的( <u>局部符号</u> ，只对定义该符号的模块可见)，有些是全局的( <u>全局符号</u> ，对其他模块可见)。</p>

<ul>
<li><strong>局部符号</strong>：每个模块中每个局部符号有一个定义</li>
<li><p><strong>全局符号</strong>：可重定位目标文件的符号表里的全局符号是区分<strong>强</strong>和<strong>弱</strong>的，链接器根据以下规则来处理多重定义的符号名：</p>
<ul>
<li>规则1: 不允许有多个同名的强符号</li>
<li>规则2: 如果有一个强符号和多个弱符号同名，那么选择强符号</li>
<li>规则3：如果有多个弱符号同名，那么任选一个 </li>
</ul></li>
</ul>

<h2 id="toc_6">7 重定位</h2>

<p>重定位合并输入模块，并为每个符号分配运行时地址：</p>

<ul>
<li>重定位节和符号定义：将所有相同类型的节合并为同一类型的新的聚合节，并将运行时内存地址赋给新的聚合节和每个符号定义。
<ul>
<li>例如，来自所有输入模块的<code>.data</code>节被全部合并成输出的可执行目标文件的<code>.data</code>节<br/></li>
</ul></li>
<li>重定位节中的符号引用：将运行时地址付给每个符号引用</li>
</ul>

<h2 id="toc_7">8 可执行目标文件</h2>

<p>下图概括了一个典型的ELF可执行文件的给类信息。</p>

<p><img src="media/15151885614329/%E5%8F%AF%E6%89%A7%E8%A1%8C%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6.png" alt="可执行目标文件"/></p>

<h2 id="toc_8">9 加载可执行目标文件</h2>

<p>当在shell中执行目标文件时，首先通过调用<strong>加载器</strong>(<code>loader</code>)的操作系统代码来运行它，加载器将可执行目标文件的代码和数据复制到主存，跳转到程序的第一条指令(入口点，<code>_start_</code>函数的地址)运行该程序。</p>

<p>在Unix系统中，加载器是系统调用(system call)<code>execve()</code>的回调(call back)，其任务包括：</p>

<ul>
<li>确认(权限，内存要求等)</li>
<li>复制程序到主存</li>
<li>复制命令行参数到栈</li>
<li>初始化寄存器(例如栈针)</li>
<li>跳到入口点(<code>_start_</code>)</li>
</ul>

<h2 id="toc_9">10 动态链接共享库</h2>

<p>静态库有2大缺陷：</p>

<ul>
<li>静态库更新时，需要显示地将程序与更新了的库重新链接</li>
<li>浪费内存资源：几乎每个C程序都使用标准I/O函数，这些函数代码会被复制到每个运行进程的文本段中</li>
</ul>

<p>共享库(shared library)是致力于解决静态库缺陷的产物。</p>

<p><strong>动态链接</strong>(dynamic linking)：共享库在运行或加载时，可以加载到任意的内存地址，并和一个在内存中的程序链接起来。</p>

<ul>
<li>由动态链接器(dynamic linke)执行；</li>
<li>在linux系统中常用<code>.so</code>后缀表示。</li>
</ul>

<p><img src="media/15151885614329/dynamic_linking.png" alt="dynamic_linking"/></p>

<h2 id="toc_10">14 处理目标文件的工具</h2>

<p>Unix系统提供了一系列命令帮助理解和处理目标文件。这些工具包括：</p>

<ul>
<li><code>ar</code> ：创建静态库，插入、删除、列出和提取成员；</li>
<li><code>STRINGS</code> ：列出目标文件中所有可以打印的字符串；</li>
<li><code>STRIP</code> ：从目标文件中删除符号表信息；</li>
<li><code>NM</code> ：列出目标文件符号表中定义的符号；</li>
<li><code>SIZE</code> ：列出目标文件中节的名字和大小；</li>
<li><code>READELF</code> ：显示一个目标文件的完整结构，包括ELF 头中编码的所有信息。</li>
<li><code>OBJDUMP</code> ：显示目标文件的所有信息，最有用的功能是反汇编.text节中的二进制指令。</li>
<li><code>LDD</code> ：列出可执行文件在运行时需要的共享库。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Intro to Hadoop and MapReduce]]></title>
    <link href="http://larryim.cc/hadoop_mapreduce.html"/>
    <updated>2018-07-15T00:06:54+08:00</updated>
    <id>http://larryim.cc/hadoop_mapreduce.html</id>
    <content type="html"><![CDATA[
<p>The content of the note from the course, Intro to Hadoop and MapReduce, on <a href="https://cn.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617">Udacity</a>.</p>

<h3 id="toc_0">2 data source</h3>

<p>data increases</p>

<ul>
<li>phone data</li>
<li>online store</li>
</ul>

<p>how to store and process large amounts of data?</p>

<h3 id="toc_1">3. big data</h3>

<p>what is big data?</p>

<ul>
<li>order details for a store</li>
<li>all orders across 100s of stores</li>
<li>a person&#39;s stock portfoio</li>
<li>all stock transaction for the new york</li>
</ul>

<h3 id="toc_2">4. big data solution</h3>

<p>big data:</p>

<ul>
<li>all orders across 100s of stores</li>
<li>all stock transaction for the new york</li>
</ul>

<h3 id="toc_3">5. Definition of Big Data</h3>

<p>big data is data that is too big to process on a single machine</p>

<h3 id="toc_4">6 challenges</h3>

<ul>
<li>most data is worthless. false</li>
<li>data is created fast. true</li>
<li>data from different sources in various formats. true</li>
</ul>

<h3 id="toc_5">8 the 3vs</h3>

<ul>
<li>volumes: size of data 
<ul>
<li>reliable storage: find a cheaper way </li>
</ul></li>
<li>variety: data coming from  different source and format</li>
<li>velocity: speed of data generation</li>
</ul>

<h3 id="toc_6">9 data worth storing?</h3>

<ul>
<li>transactions</li>
<li>logs</li>
<li>business</li>
<li>user</li>
<li>sensor</li>
<li>medical</li>
<li>social</li>
</ul>

<p>all </p>

<h3 id="toc_7">11 variety</h3>

<p>data variety. for a long time, people use sql, mysql, oracle to store their data. the problem is that data needs to be fit in pre-defined tables. and a lot of data we deal these days tend to be unstructured or semi-structured data</p>

<h2 id="toc_8">15 velocity</h2>

<p>TB/day</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - 异常控制流]]></title>
    <link href="http://larryim.cc/exceptional_control_flow.html"/>
    <updated>2018-07-10T17:24:32+08:00</updated>
    <id>http://larryim.cc/exceptional_control_flow.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">1 异常</a>
<ul>
<li>
<a href="#toc_1">1.1 异常的处理</a>
</li>
<li>
<a href="#toc_2">1.2 异常的类别</a>
</li>
</ul>
</li>
<li>
<a href="#toc_3">2 进程</a>
<ul>
<li>
<a href="#toc_4">2.1 逻辑控制流</a>
</li>
<li>
<a href="#toc_5">2.2 并发流</a>
</li>
<li>
<a href="#toc_6">2.3 私有地址空间</a>
</li>
<li>
<a href="#toc_7">2.4 用户模式和内核模式</a>
</li>
</ul>
</li>
<li>
<a href="#toc_8">3 系统调用错误处理</a>
</li>
<li>
<a href="#toc_9">4 进程控制</a>
<ul>
<li>
<a href="#toc_10">4.1 获取进程ID</a>
</li>
<li>
<a href="#toc_11">4.2 创建和终止进程</a>
</li>
<li>
<a href="#toc_12">4.3 回收子进程</a>
</li>
<li>
<a href="#toc_13">4.4 进程休眠</a>
</li>
<li>
<a href="#toc_14">4.5  加载并运行程序</a>
</li>
</ul>
</li>
<li>
<a href="#toc_15">5 信号</a>
<ul>
<li>
<a href="#toc_16">5.1 发送/接收信号</a>
</li>
<li>
<a href="#toc_17">5.2 发送信号</a>
</li>
<li>
<a href="#toc_18">5.3 接收信号</a>
</li>
<li>
<a href="#toc_19">5.4 阻塞信号和进程回收</a>
<ul>
<li>
<a href="#toc_20">5.4.1 隐式阻塞机制</a>
</li>
<li>
<a href="#toc_21">5.4.2 显式阻塞机制</a>
</li>
</ul>
</li>
<li>
<a href="#toc_22">5.5 信号处理程序</a>
</li>
</ul>
</li>
</ul>


<p>从给处理器加电开始，直到你断电为止，程序计数器假设成一个值的序列</p>

<p>\[a_0, a_1, ..., a_{n-1}\]</p>

<p>其中，每个\(a_k\)是某个相应的指令\(I_k\)的 <u>地址</u> 。每次从\(a_k\)到\(a_{k+1}\)的过渡称为<strong>控制转移</strong>(control transfer)。这样的控制转移序列叫做处理器的<strong>控制流</strong>(control flow)。</p>

<p>现在系统通过使控制流发生突变来应对系统状态的变化(eg.缺页异常，网络等待)，把这些突变称为<strong>异常控制流</strong>(Exceptional Control Flow, ECF)。</p>

<h2 id="toc_0">1 异常</h2>

<h3 id="toc_1">1.1 异常的处理</h3>

<p>系统为每<strong>类</strong>可能的异常都分配了一个唯一的非负整数的<strong>异常号</strong>(exception number)。在系统启动时，操作系统分配和初始化一张称为<strong>异常表</strong>的跳转表，使得表目\(k\)包含异常\(k\)的处理程序的地址。</p>

<p><img src="media/15312146721582/%E5%BC%82%E5%B8%B8%E8%A1%A8.png" alt="异常表"/></p>

<p>当检测到发生了一个事件，并且确定了相应的异常号\(k\)，处理器触发异常，执行间接过程调用，通过异常表的表目\(k\)，转到相应的处理程序。</p>

<h3 id="toc_2">1.2 异常的类别</h3>

<p>异常(exceptions)可以分为四类：中断(interrupt)、陷阱(trap)、故障(fault)和终止(abort)。<br/>
<img src="media/15312146721582/Exceptions.png" alt="Exceptions"/></p>

<ul>
<li><strong>中断</strong>是异步发生的，是来自处理器外部的I/O设备的信号的结果。</li>
<li><strong>陷阱</strong>是有意的异常，是执行一条指令的结果。
<ul>
<li>其用途是在用户程序和内核之间提供一个像过程一样的接口(系统调用)</li>
</ul></li>
<li><strong>故障</strong>是由错误情况引起的，可能能够被故障处理程序修正。
<ul>
<li>例如缺页异常</li>
</ul></li>
<li><strong>终止</strong>是不可恢复的致命错误造成的结果，通常是一些硬件错误。<br/></li>
</ul>

<h2 id="toc_3">2 进程</h2>

<p>进程(Process)的经典定义就是 <u>一个执行中程序的实例</u> (A process is a program in execuation) 。系统中的每个程序都运行在某个进程的上下文(context)中。上下文是由程序正确运行所需的状态组成的。这个状态包括存放在内存中的程序的代码和数据，它的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述符的集合。</p>

<p>进程提供了应用程序两个关键抽象：</p>

<ul>
<li>一个<strong>独立</strong>的逻辑控制流，它提供一个假象，好像我们的程序独占地使用处理器。</li>
<li>一个<strong>私有</strong>的地址空间，它提供一个假象，好像我们的程序独占地使用内存系统。</li>
</ul>

<h3 id="toc_4">2.1 逻辑控制流</h3>

<p><strong>逻辑控制流</strong>(Logical Control Flow，简称逻辑流)是PC值的序列。</p>

<h3 id="toc_5">2.2 并发流</h3>

<p>一个逻辑流的执行在时间上与另一个流重叠，称为<strong>并发流</strong>(concurrent flow)，这两个流被称为<strong>并发地运行</strong>。</p>

<h3 id="toc_6">2.3 私有地址空间</h3>

<p>进程为每个程序提供它自己的<strong>私有地址空间</strong>。一般而言，和这个空间中某个地址相关联的那个内存字节是不能被其他进程读或者写的，从这个意义上说，这个地址空间是私有的。</p>

<h3 id="toc_7">2.4 用户模式和内核模式</h3>

<p>处理器通常是用某个控制寄存器中的一个<strong>模式位</strong>(mode bit)来控制用户/内核模式。当设置了模式位时，进程就运行在<strong>内核模式</strong>中，否则运行在<strong>用户模式</strong>中。</p>

<p>运行在内核模式的进程可以执行指令集中的任何指令，可以访问任何内存位置。用户模式中的进程不允许执行特权指令，也不允许直接引用地址空间中内核区的代码和数据。</p>

<h2 id="toc_8">3 系统调用错误处理</h2>

<h2 id="toc_9">4 进程控制</h2>

<p>进程控制包括获取进程ID、创建和终止进程、回收子进程、让进程休眠、加载并运行程序等。这一节将描述Unix提供了控制进程的系统调用。</p>

<h3 id="toc_10">4.1 获取进程ID</h3>

<p>每一个进程都有一个唯一的整数(非零)进程ID(PID)。<code>getpid</code>函数返回调用进程的PID。<code>getppid</code>函数返回它的父进程的PID。</p>

<pre><code class="language-c">#include &lt;sys/types.h&gt;
#include &lt;unistd.h&gt;

pid_t getpid(void);
pit_t getppid(void);
</code></pre>

<h3 id="toc_11">4.2 创建和终止进程</h3>

<p><strong>父进程</strong>通过调用fork函数创建一个新的运行的<strong>子进程</strong>。</p>

<pre><code class="language-c">#include &lt;sys/types.h&gt;
#include &lt;unistd.h&gt;

pid_t fork(void);
</code></pre>

<p>新创建的子进程几乎但不完全与父进程相同：</p>

<ul>
<li><strong>相同但是独立的地址空间</strong>：子进程获得父进程虚拟地址空间的一份副本</li>
<li><strong>共享文件</strong>：子进程获得父进程打开文件描述符相同的副本</li>
<li>子进程与父进程pid不同</li>
</ul>

<h3 id="toc_12">4.3 回收子进程</h3>

<p>进程在终止后，并不会被内核从系统中清除，而是保持这种状态，直到被它的父进程<strong>回收</strong>(reaped)。</p>

<ul>
<li>一个终止了但还未被回收的进程称为<strong>僵死进程</strong>(zombie)。</li>
<li>即使僵死进程没有运行，它仍然消耗系统的内存资源。</li>
</ul>

<p>通过调用<code>waitpid</code>函数来等待子进程终止或者停止。</p>

<h3 id="toc_13">4.4 进程休眠</h3>

<p><code>sleep</code>函数将一个进程挂起一段制定的时间。</p>

<pre><code class="language-c">#include &lt;unistd.n&gt;
unsigned int sleep(unsigned int secs);
</code></pre>

<h3 id="toc_14">4.5  加载并运行程序</h3>

<p><code>execve</code>函数在当前进程的上下文中加载并运行一个新程序。</p>

<ul>
<li><code>execve</code>调用一次并从不返回。</li>
</ul>

<h2 id="toc_15">5 信号</h2>

<p>Linux<strong>信号</strong>，通知进程系统中发生一个某种类型的事件。每种信号类型都对应于某种系统事件。低层的硬件异常是由内核异常处理程序处理的，正常情况下，对用户进程而言是不可见的。下面是Linux系统上常见的信号：</p>

<p><strong>常见的信号</strong>：</p>

<table>
<thead>
<tr>
<th>编号</th>
<th>名称</th>
<th>默认动作</th>
<th>对应事件</th>
</tr>
</thead>

<tbody>
<tr>
<td>2</td>
<td>SIGINT</td>
<td>终止</td>
<td>来自键盘的中断CTRL+C</td>
</tr>
<tr>
<td>3</td>
<td>SIGQUIT</td>
<td>终止</td>
<td>来自键盘的退出CTRL+\</td>
</tr>
<tr>
<td>9</td>
<td>SIGKILL</td>
<td>终止</td>
<td>杀死程序 <code>\bin\kill -9</code></td>
</tr>
<tr>
<td>11</td>
<td>SIGSEGV</td>
<td>终止并转储内存</td>
<td>段故障(无效的内存引用)</td>
</tr>
<tr>
<td>15</td>
<td>SIGTERM</td>
<td>终止</td>
<td>软件终止信号<code>\bin\kill</code></td>
</tr>
<tr>
<td>17</td>
<td>SIGCHLD</td>
<td>忽略</td>
<td>子进程停止或终止</td>
</tr>
<tr>
<td>18</td>
<td>SIGCONT</td>
<td>忽略</td>
<td>继续进程如果该进程停止</td>
</tr>
<tr>
<td>20</td>
<td>SIGTSTP</td>
<td>停止直到下一个SIGCONT</td>
<td>用户输入CTRL+Z</td>
</tr>
</tbody>
</table>

<p>详细信息可以通过<code>man 7 signal</code>查询。</p>

<h3 id="toc_16">5.1 发送/接收信号</h3>

<p>传送一个信号到目的进程由发送、接收信号两个步骤组成：</p>

<ul>
<li>发送信号。内核通过更新目的进程上下文中的某个状态，发送(递送)一个信号给目的进程。</li>
<li>接收信号。当目的进程被内核强迫已某种方式对信号的发送做出反应时，它就接收了信号。进程可以忽略这个信号，终止或者通过执行一个称为<strong>信号处理程序</strong>的用户层函数捕获这个信号。</li>
</ul>

<h3 id="toc_17">5.2 发送信号</h3>

<p>发送信号可以由以下原因引起：</p>

<ul>
<li>用户：用户能够通过输入<code>CTRL+c</code>(<code>SIGINT</code>)、<code>Ctrl+z</code>(<code>SIGTSTP</code>)，或者是终端驱动程序分配给信号控制字符的其他任何键来请求内核产生信号；</li>
<li>内核：当进程执行出错时，内核会给进程发送一个信号，例如非法段存取(内存访问违规)、浮点数溢出等；</li>
<li>进程：一个进程可以通过系统调用kill给另一个进程或自己发送信号。</li>
</ul>

<h3 id="toc_18">5.3 接收信号</h3>

<p>当内核把进程\(p\)从内核模式切换到用户模式时，它会检查进程\(p\)的未被阻塞的待处理信号的集合(<code>pending&amp;~blocked</code>,见下文)，如果集合非空，那么内核强制\(p\)接收信号，触发进程采取某种行为。</p>

<p>进程接收到信号以后，可以有如下3种选择进行处理：</p>

<ul>
<li>接收默认处理：接收默认处理的进程通常会导致进程本身消亡。例如连接到终端的进程，用户按下CTRL+c，将导致内核向进程发送一个SIGINT的信号，进程如果不对该信号做特殊的处理，系统将采用默认的方式处理该信号，即终止进程的执行；</li>
<li>忽略信号：进程可以通过代码，显示地忽略某个信号的处理，例如：<code>signal(SIGINT,SIGDEF)</code>；但是某些信号是不能被忽略的，</li>
<li>捕获信号并处理：当接收到信号时，由信号处理程序自动捕获并且处理信号。</li>
</ul>

<pre><code class="language-c">sighandler_t signal(int signum, sighandler_t handler);
</code></pre>

<p>有两个信号既不能被忽略也不能被捕获，它们是<code>SIGKILL</code>和<code>SIGSTOP</code>。即进程接收到这两个信号后，只能接受系统的默认处理，即终止线程。</p>

<h3 id="toc_19">5.4 阻塞信号和进程回收</h3>

<p>一个发出而没有被接受的信号叫做<strong>未处理信号</strong>（Pending Signal）。进程可以选择阻塞（Block）某个信号。被阻塞的信号产生时将保持在未处理状态，直到进程解除对此信号的阻塞，才执行接收的动作。阻塞和忽略是不同的，<strong>只要信号被阻塞就不会接收</strong>，而忽略是在接收之后可选的一种处理动作。</p>

<p>Linux提供阻塞信号的隐式和显式机制:</p>

<ul>
<li><strong>隐式阻塞机制</strong>：内核默认阻塞任何当前处理程序正在处理信号类型的待处理的信号。如果在进程解除对某信号的阻塞之前这种信号产生过多次，只计一次。因为每个信号只有一个bit的未处理标志(如下图)，非0即1，不记录该信号产生了多少次，阻塞标志也是这样表示的。</li>
<li><strong>显式阻塞机制</strong>：应用<code>sigprocmask</code>函数，明确地阻塞和解除阻塞选定的信号。</li>
</ul>

<p>内核为每个进程在<strong>pending位向量</strong>中维护着待处理信号的集合，而在<strong>blocked位向量</strong>中维护着被阻塞的信号集合。信号在内核中的表示可以看作是这样的：</p>

<p><img src="media/15156057194882/15156070945641.png" alt=""/></p>

<p>每个信号都有两个标志位分别表示阻塞和未处理，还有一个函数指针表示处理动作。信号产生时，内核在进程控制块中设置该信号的未处理标志，直到信号接收才清除该标志。在上图的例子中，</p>

<ul>
<li>SIGHUP信号未阻塞也未产生过，当它接收时执行默认处理动作。</li>
<li>SIGINT信号产生过，但正在被阻塞，所以暂时不能接收。虽然它的处理动作是忽略，但在没有解除阻塞之前不能忽略这个信号，因为进程仍有机会改变处理动作之后再解除阻塞。</li>
<li>SIGQUIT信号未产生过，一旦产生SIGQUIT信号将被阻塞，它调用信号处理程序<code>sighandler</code>。</li>
</ul>

<h4 id="toc_20">5.4.1 隐式阻塞机制</h4>

<p>当多个未处理信号(<code>pending signal</code>)到达时，由于信号并不会产生排队等待这样的情况，所以产生的效果仅相当于一个未处理信号(也就是对应的<code>pending</code>位标记为1，例如上图中的<code>SIGINT</code>信号)。</p>

<p>这样带来几个问题：</p>

<ul>
<li>不能用信号来对其他进程中发生的事件计数，这是显而易见的</li>
<li>在回收子进程时，要回收尽可能多的子进程。例如下面这个例子。</li>
</ul>

<pre><code class="language-c">void handler1(int sig)   
{  
    pid_t pid;  
  
    if ((pid = waitpid(-1, NULL, 0)) &lt; 0)  
        unix_error(&quot;waitpid error&quot;);  
    printf(&quot;Handler reaped child %d\n&quot;, (int)pid);  
    Sleep(2);  
    return;  
}  

/* $begin signal2 */
void handler2(int sig) 
{
    int olderrno = errno;

    while (waitpid(-1, NULL, 0) &gt; 0) {
        Sio_puts(&quot;Handler reaped child\n&quot;);
    }
    // waitpid()函数有可能因为找不到子进程而报ECHILD错误
    if (errno != ECHILD)
        Sio_error(&quot;waitpid error&quot;);
    Sleep(1);
    errno = olderrno;
}
/* $end signal2 */

int main() 
{
    int i, n;
    char buf[MAXBUF];

    if (signal(SIGCHLD, handler2) == SIG_ERR) //handler2 或者 handler1
        unix_error(&quot;signal error&quot;);

    /* Parent creates children */
    for (i = 0; i &lt; 3; i++) {
        if (Fork() == 0) {
            printf(&quot;Hello from child %d\n&quot;, (int)getpid());
            exit(0);
        }
    }

    /* Parent waits for terminal input and then processes it */
    if ((n = read(STDIN_FILENO, buf, sizeof(buf))) &lt; 0)
        unix_error(&quot;read&quot;);

    printf(&quot;Parent processing input\n&quot;);
    while (1)
        ;

    exit(0);
}
</code></pre>

<p>在上面这个例子中，父进程创建一些子进程，这些子进程各自独立运行一段时间，然后终止。用<code>SIGCHLD</code>处理程序来回收子进程，其中<code>handler1</code>是错误的，会产生僵死子进程。<code>handler2</code>是安全的。原因是在<code>handler1</code>中，可能存在子进程先被执行，产生<code>SIGCHLD</code>信号；但是在子进程还未被回收之前，又有多个子进程被执行，产生多个<code>SIGCHLD</code>信号。于是多余的未处理<code>SIGCHLD</code>信号就被抛弃，只相当于一个<code>SIGCHLD</code>信号。最终会造成有的子进程未被回收，产生僵死子进程。</p>

<p>执行的可能结果如下，可以看到父进程只回收了两个子进程。</p>

<pre><code class="language-text">Hello from child 5617
Hello from child 5616
Hello from child 5618
Handler reaped child
Handler reaped child

Parent processing input
</code></pre>

<h4 id="toc_21">5.4.2 显式阻塞机制</h4>

<p>有时候不希望在发送信号后就立即去接收、处理信号，同时也不希望忽略该信号，那么可以通过<code>sigprocmask</code>显式地阻塞信号从而实现延迟接收信号。</p>

<p>函数<code>sigprocmask</code>可以更改当前阻塞的信号集合(即blocked位向量):</p>

<pre><code class="language-c">int sigprocmask(int how, const sigset_t *set, sigset_t *oldset);
</code></pre>

<p>其具体行为依赖于how值：</p>

<pre><code class="language-text">SIG_BLOCK, blocked = blocked | set //添加set信号
SIG_UNBLOCK, blocked = blocked &amp; ~set //删除set信号
SIG_SETMASK, block = set //设置set信号为阻塞的信号
</code></pre>

<p>阻塞的信号集合其实就是一个无符号整型数组(在x86-64上，数组长度是16)。</p>

<pre><code class="language-c">/* A `sigset_t&#39; has a bit for each signal.  */
# define _SIGSET_NWORDS (1024 / (8 * sizeof (unsigned long int)))
typedef struct
{
    unsigned long int __val[_SIGSET_NWORDS];
} sigset_t;
</code></pre>

<p>还有其他的一些函数可以对信号集进行操作：</p>

<pre><code class="language-c">int sigfillset(sigset_t *set); // 信号集初始化, 然后把所有的信号加入到此信号集里
int sigemptyset(sigset_t *set); //信号集初始化为空
int sigaddset(sigset_t *set, int signo); //将信号signo添加到信号集中  
</code></pre>

<p>下面看个例子, 是一个具有细微同步错误的SHELL程序。如果子进程在父进程能够开始运行前就结束了，那么<br/>
<code>addjob()</code> 和 <code>deletejob()</code> 会以错误的方式被调用。这个程序希望父进程在一个作业列表中记录着它的当前子进程，每个作业条目。 <code>addjob()</code> 和 <code>deletejob()</code> 分别想这个作业列表添加和从中删除作业。当父进程创建一个新的子进程时，它就把这个子进程添加到作业列表中。当父进程在<code>SIGCHLD</code> 处理程序中回收一个终止的（僵死）子进程时，它就从作业列表中删除这个子进程。乍一看，这段代码是对的。不幸的是，可能发生下面的情况：</p>

<ul>
<li>1. 父进程执行<code>fork()</code>，内核调度新创建的子进程运行，而不是父进程</li>
<li>2. 在父进程能够再次运行之前，子进程就终止，并且变成一个僵死进程，使得内核传递一个<code>SIGCHLD</code>信号给父进程</li>
<li>3. 后来，当父进程再次变成可运行但又在它执行之前，内核注意到待处理的<code>SIGCHLD</code>信号，并通过在父进程中运行处理程序接收这个信号</li>
<li>4. 处理程序回收终止的子进程，并调用<code>deletejob()</code>，这个函数什么都不做，因为父进程还没有把该子进程添加到列表中</li>
<li>5. 在处理程序运行结束后，内核运行父进程，父进程从<code>fork()</code>返回，通过调用<code>addjob()</code> 错误地把（不存在的）子进程添加到作业列表中</li>
</ul>

<pre><code class="language-c">void handler(int sig)
{
        pid_t pid;
        while ((pid = waitpid(-1, NULL, 0)) &gt; 0) /* Reap a zombie child */
                deletejob(pid); /* Delete the child from the job list */
        if (errno != ECHILD)
                unix_error(&quot;waitpid error&quot;);
}

int main(int argc, char **argv)
{
        int pid;

        Signal(SIGCHLD, handler);
        initjobs();             /* Initialize the job list */

        while (1) {
                /* Child process */
                if ((pid = Fork()) == 0) {
                        Execve(&quot;/bin/date&quot;, argv, NULL);
                }

                /* Parent process */
                addjob(pid);    /* Add the child to the job list */
        }

        exit(0);
}
</code></pre>

<p>正确的做法应该如下,  通过在调用 <code>fork()</code> 之前，阻塞 <code>SIGCHLD</code> 信号，然后在我们调用了 <code>addjob()</code> 之后就取消阻塞这些信号，我们保证了在子进程被添加到作业列表之后回收该子进程。注意，子进程继承了它们父进程的被阻塞集合，所以我们必须在调用 <code>execve()</code> 之前，小心地解除子进程中阻塞的 <code>SIGCHLD</code> 信号。这样，父进程保证在相应的 <code>deletejob()</code> 之前执行 <code>addjob()</code>。</p>

<pre><code class="language-c">int main(int argc, char **argv)
{
    int pid;
    sigset_t mask_all, mask_one, prev_one;

    Sigfillset(&amp;mask_all);
    Sigemptyset(&amp;mask_one);
    Sigaddset(&amp;mask_one, SIGCHLD);
    Signal(SIGCHLD, handler);
    initjobs(); /* Initialize the job list */

    while (1) {
        Sigprocmask(SIG_BLOCK, &amp;mask_one, &amp;prev_one); /* Block SIGCHLD */
        if ((pid = Fork()) == 0) { /* Child process */
            Sigprocmask(SIG_SETMASK, &amp;prev_one, NULL); /* Unblock SIGCHLD */
            Execve(&quot;/bin/date&quot;, argv, NULL);
        }
        Sigprocmask(SIG_BLOCK, &amp;mask_all, NULL); /* Parent process */  
        addjob(pid);  /* Add the child to the job list */
        Sigprocmask(SIG_SETMASK, &amp;prev_one, NULL);  /* Unblock SIGCHLD */
    }
    exit(0);
}
</code></pre>

<h3 id="toc_22">5.5 信号处理程序</h3>

<p>信号处理程序(signal handler)是重要且棘手的一个问题。其难点在：</p>

<ul>
<li>处理程序与主程序并发运行，共享同样的全局变量，因此可能与主程序和其他处理程序相互干扰；</li>
<li>如何以及何时接收信号的规则常常违背人的直觉。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Overhead]]></title>
    <link href="http://larryim.cc/overhead.html"/>
    <updated>2018-01-21T12:39:28+08:00</updated>
    <id>http://larryim.cc/overhead.html</id>
    <content type="html"><![CDATA[
<p><strong>overhead</strong>这个词在计算机中经常出现，那么它到底是什么意思呢？</p>

<p>overhead视风格可以翻译成「额外开销」、「额外消耗」、「虚耗」。</p>

<p>额外开销是建立一个操作所需的资源，它可能看起来不相关，但是却是必须的。就好像当你需要去某个地方的时候，你可能需要一辆车。但是如果你开车上街这件事是大量的额外开销，你可能会想要走路；但是如果你要开车穿越一个国家，额外开销是值得的。</p>

<p>The meaning of the word can differ a lot with context. In general, it&#39;s resources (most often memory and CPU time) that are used, which do not contribute directly to the intended result, but are required by the technology or method that is being used. Examples:</p>

<ul>
<li><p>Protocol overhead: Ethernet frames, IP packets and TCP segments all have headers, TCP connections require handshake packets. Thus, you cannot use the entire bandwidth the hardware is capable of for your actual data. You can reduce the overhead by using larger packet sizes and UDP has a smaller header and no handshake.</p></li>
<li><p>Data structure memory overhead: A linked list requires at least one pointer for each element it contains. If the elements are the same size as a pointer, this means a 50% memory overhead, whereas an array can potentially have 0% overhead.</p></li>
<li><p>Method call overhead: A well-designed program is broken down into lots of short methods. But each method call requires setting up a stack frame, copying parameters and a return address. This represents CPU overhead compared to a program that does everything in a single monolithic function. Of course, the added maintainability makes it very much worth it, but in some cases, excessive method calls can have a significant performance impact.</p></li>
</ul>

<h2 id="toc_0">参考</h2>

<ul>
<li><a href="https://stackoverflow.com/questions/2860234/what-is-overhead">https://stackoverflow.com/questions/2860234/what-is-overhead</a></li>
<li><a href="https://www.zhihu.com/question/20596199?sort=created">https://www.zhihu.com/question/20596199?sort=created</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - x86-64汇编]]></title>
    <link href="http://larryim.cc/15146536465849.html"/>
    <updated>2017-12-31T01:07:26+08:00</updated>
    <id>http://larryim.cc/15146536465849.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">汇编代码格式</h2>

<p>现在主要存在<code>ATT</code>和<code>Intel</code>两种汇编代码格式。<code>ATT</code>格式是<code>GCC</code>、 <code>OBJDUMP</code>常用工具的默认格式。其他的诸如Microsoft的工具和来自Intel的文档都是<code>Intel</code>格式的。本文使用<code>ATT</code>格式。</p>

<p><code>ATT</code>汇编格式的注释格式有两种</p>

<pre><code class="language-text"># this is a comment
/* this is a comment */
</code></pre>

<h2 id="toc_1">寄存器</h2>

<p><code>x86-64</code>体系结构广泛存在于个人电脑中。它拥有16个整数寄存器，分别存储64位的值。这些寄存器可以存储地址或整数数据，其分布如下：</p>

<p><img src="media/15146536465849/sfd.png" alt="sfd"/></p>

<p>根据惯例，寄存器%rbx, %rbp和%r12~%r15被划分为<strong>被调用者保存寄存器</strong>。所有其他的寄存器，除了栈指针%rsp都分类为<strong>调用者保存寄存器</strong>。</p>

<ul>
<li>在函数被调用时，不能改变<strong>被</strong>调用者寄存器；</li>
<li>如果要改变的话，只能把<strong>被</strong>调用者寄存器的值压入栈中，在使用后，从栈中恢复<strong>被</strong>调用者寄存器。</li>
</ul>

<h3 id="toc_2">rip 寄存器与PC相对寻址</h3>

<p>%rip 的名称来自于(instruction pointer register，指令指针寄存器)。%rip其实就是<strong>程序计数器</strong>(Program Counter, PC), <u><em>存放着下一条指令的地址</em></u> 。不可以直接修改%rip。</p>

<p>-&gt; <code>instruction pointer = program counter = %rip</code></p>

<p>%rip的其他很重要的一个用法就是RIP/<strong>PC相对寻址</strong>(RIP/PC relative addressing)。即<code>%rip + displacement</code>的用法。</p>

<p>例如，</p>

<pre><code class="language-assembly">mov    0x202a62(%rip),%rdi        # 6044d0 &lt;infile&gt;  rdi = infile
</code></pre>

<p>表示传输%rip+0x202a62的地址对应的内存上的内容到%rdi。</p>

<p>下面说说它是怎么进行PC相对寻址的。</p>

<ul>
<li>源文件经过预处理器、编译器、汇编器处理，输出<strong>可重定位目标文件</strong></li>
<li>再经过<strong>符号解析</strong>(Symbol resolution)把代码中的每个符号引用和一个符号定义关联起来之后，要完成<strong>重定位</strong>(Relocation)任务，最终输出<strong>可执行目标文件</strong>。
<ul>
<li>在<strong>重定位</strong>阶段，ELF(可重定位目标文件在LINUX系统上的一种格式)文件中的<code>R_X86_64_PC32</code>重定位类型重定位了一个使用32位PC相对地址的引用。</li>
<li>当CPU执行一条使用PC相对寻址的指令时，它就将在指令中编码的32位值加上PC的当前运行时值，得到<strong>有效地址</strong>。</li>
</ul></li>
</ul>

<h2 id="toc_3">指令</h2>

<p>指令主要有<code>mov</code>数据传送指令，<code>push</code>、<code>pop</code>压入和压出栈数据，<code>add</code>,<code>sub</code>等算数操作指令，<code>ret</code>, <code>call</code>等转移控制指令。</p>

<h3 id="toc_4">数据传送指令</h3>

<table>
<thead>
<tr>
<th>指令</th>
<th>效果</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>MOV S, D</td>
<td>将S中数据传送到D中</td>
<td>传送</td>
</tr>
<tr>
<td>movb</td>
<td>传送字节</td>
<td></td>
</tr>
<tr>
<td>movw</td>
<td>传送字(双字节)</td>
<td></td>
</tr>
<tr>
<td>movl</td>
<td>传送双字(四字节)</td>
<td></td>
</tr>
<tr>
<td>MOVS S, D</td>
<td>将S中数据传送到D，过程中做了符号扩展处理 传送需要符号扩展的字节</td>
<td></td>
</tr>
<tr>
<td>movsbw</td>
<td>将做了符号扩展的字节传送到字</td>
<td></td>
</tr>
<tr>
<td>movsbl</td>
<td>将做了符号扩展的字节传送到双字</td>
<td></td>
</tr>
<tr>
<td>movswl</td>
<td>将做了符号扩展的字传送到双字</td>
<td></td>
</tr>
<tr>
<td>MOVZ S, D</td>
<td>将S中数据传送到D，过程中做了零扩展处理</td>
<td>传送需要零扩展的字节</td>
</tr>
<tr>
<td>movzbw</td>
<td>将做了零扩展的字节传送到</td>
<td></td>
</tr>
<tr>
<td>movzbl</td>
<td>将做了零扩展的字节传送到双字</td>
<td></td>
</tr>
<tr>
<td>movzwl</td>
<td>将做了零扩展的字传送到双字</td>
<td></td>
</tr>
<tr>
<td>pushl S</td>
<td>R[%esp] &lt;- R[%esp] - 4; M[R[%esp]] &lt;- S;</td>
<td>将双字压栈</td>
</tr>
<tr>
<td>popl D</td>
<td>D &lt;- M[R[%esp]]; R[%esp] &lt;- R[%esp] + 4;</td>
<td>将双字出栈</td>
</tr>
</tbody>
</table>

<h3 id="toc_5">ret, call指令</h3>

<p>在x86-64上，<code>ret</code>指令，相当于从栈中弹出地址A，然后把PC设置为A。<br/>
<code>pop %rip</code><br/>
而<code>call</code>指令，刚好相反，把%rip 压入栈中，然后跳到函数对应的地址。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSE 421/521 Operating Systems]]></title>
    <link href="http://larryim.cc/15312166852240.html"/>
    <updated>2018-07-10T17:58:05+08:00</updated>
    <id>http://larryim.cc/15312166852240.html</id>
    <content type="html"><![CDATA[
<p>主页：<a href="https://www.ops-class.org">https://www.ops-class.org</a><br/>
Notes: </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Objdump 反汇编]]></title>
    <link href="http://larryim.cc/objdump_disassembler.html"/>
    <updated>2018-01-01T03:54:09+08:00</updated>
    <id>http://larryim.cc/objdump_disassembler.html</id>
    <content type="html"><![CDATA[
<p><code>objdump</code>是一个反汇编器(<code>disassembler</code>)，可以将机器语言生成对应的汇编文件。常用的命令是</p>

<pre><code class="language-text">objdump -d filename.o
</code></pre>

<p>其选项有：</p>

<pre><code class="language-text">--archive-headers 
-a 
显示档案库的成员信息,类似ls -l将lib*.a的信息列出。 

-b bfdname 
--target=bfdname 
指定目标码格式。这不是必须的，objdump能自动识别许多格式，比如： 

objdump -b oasys -m vax -h fu.o 
显示fu.o的头部摘要信息，明确指出该文件是Vax系统下用Oasys编译器生成的目标文件。objdump -i将给出这里可以指定的目标码格式列表。 

-C 
--demangle 
将底层的符号名解码成用户级名字，除了去掉所开头的下划线之外，还使得C++函数名以可理解的方式显示出来。 

--debugging 
-g 
显示调试信息。企图解析保存在文件中的调试信息并以C语言的语法显示出来。仅仅支持某些类型的调试信息。有些其他的格式被readelf -w支持。 

-e 
--debugging-tags 
类似-g选项，但是生成的信息是和ctags工具相兼容的格式。 

--disassemble 
-d 
从objfile中反汇编那些特定指令机器码的section。 

-D 
--disassemble-all 
与 -d 类似，但反汇编所有section. 

--prefix-addresses 
反汇编的时候，显示每一行的完整地址。这是一种比较老的反汇编格式。 

-EB 
-EL 
--endian={big|little} 
指定目标文件的小端。这个项将影响反汇编出来的指令。在反汇编的文件没描述小端信息的时候用。例如S-records. 

-f 
--file-headers 
显示objfile中每个文件的整体头部摘要信息。 

-h 
--section-headers 
--headers 
显示目标文件各个section的头部摘要信息。 

-H 
--help 
简短的帮助信息。 

-i 
--info 
显示对于 -b 或者 -m 选项可用的架构和目标格式列表。 

-j name
--section=name 
仅仅显示指定名称为name的section的信息 

-l
--line-numbers 
用文件名和行号标注相应的目标代码，仅仅和-d、-D或者-r一起使用使用-ld和使用-d的区别不是很大，在源码级调试的时候有用，要求编译时使用了-g之类的调试编译选项。 

-m machine 
--architecture=machine 
指定反汇编目标文件时使用的架构，当待反汇编文件本身没描述架构信息的时候(比如S-records)，这个选项很有用。可以用-i选项列出这里能够指定的架构. 

--reloc 
-r 
显示文件的重定位入口。如果和-d或者-D一起使用，重定位部分以反汇编后的格式显示出来。 

--dynamic-reloc 
-R 
显示文件的动态重定位入口，仅仅对于动态目标文件意义，比如某些共享库。 

-s 
--full-contents 
显示指定section的完整内容。默认所有的非空section都会被显示。 

-S 
--source 
尽可能反汇编出源代码，尤其当编译的时候指定了-g这种调试参数时，效果比较明显。隐含了-d参数。 

--show-raw-insn 
反汇编的时候，显示每条汇编指令对应的机器码，如不指定--prefix-addresses，这将是缺省选项。 

--no-show-raw-insn 
反汇编时，不显示汇编指令的机器码，如不指定--prefix-addresses，这将是缺省选项。 

--start-address=address 
从指定地址开始显示数据，该选项影响-d、-r和-s选项的输出。 

--stop-address=address 
显示数据直到指定地址为止，该项影响-d、-r和-s选项的输出。 

-t 
--syms 
显示文件的符号表入口。类似于nm -s提供的信息 

-T 
--dynamic-syms 
显示文件的动态符号表入口，仅仅对动态目标文件意义，比如某些共享库。它显示的信息类似于 nm -D|--dynamic 显示的信息。 

-V 
--version 
版本信息 

--all-headers 
-x 
显示所可用的头信息，包括符号表、重定位入口。-x 等价于-a -f -h -r -t 同时指定。 

-z 
--disassemble-zeroes 
一般反汇编输出将省略大块的零，该选项使得这些零块也被反汇编。 

@file 可以将选项集中到一个文件中，然后使用这个@file选项载入。
</code></pre>

<p>下面通过一个简单的例子来说明一下<code>objdump</code>的常见用法，以及它生成的文件的格式。</p>

<p>假设写一个简单的C程序<code>test.c</code>如下：</p>

<pre><code class="language-c">int foo()
{
    int a = 5;
    int b = 0;
    b = a + 3;
}
</code></pre>

<p>用<code>gcc</code>命令<code>gcc test.c -c</code>生成目标文件<code>test.o</code>后, 利用<code>objdump -d test.o &gt; test.s</code>生成类似汇编文件：</p>

<pre><code class="language-text">test.o:     file format elf64-x86-64


Disassembly of section .text:

0000000000000000 &lt;foo&gt;:
   0:   55                      push   %rbp
   1:   48 89 e5                mov    %rsp,%rbp
   4:   c7 45 f8 05 00 00 00    movl   $0x5,-0x8(%rbp)
   b:   c7 45 fc 00 00 00 00    movl   $0x0,-0x4(%rbp)
  12:   8b 45 f8                mov    -0x8(%rbp),%eax
  15:   83 c0 03                add    $0x3,%eax
  18:   89 45 fc                mov    %eax,-0x4(%rbp)
  1b:   5d                      pop    %rbp
  1c:   c3                      retq
</code></pre>

<p>可以看到的其实这个类似于汇编文件的格式是<code>elf64-x86-64</code>, 下一小节会简单的介绍这个格式。其中最重要的内容是从<code>0000000000000000 &lt;foo&gt;</code>开始到结束的部分。这部分从左到右依次是</p>

<ul>
<li>指令开始的地址<code>memory staring addresses</code></li>
<li>汇编代码对应的二进制指令<code>byte codes for instruction</code></li>
<li>汇编代码<code>assembly codes</code></li>
</ul>

<h3 id="toc_0">显示文件的符号表入口</h3>

<p><code>objdump -t</code> 命令会打印文件的符号表<code>symbol table</code>. 输出的文件一共有7列，从左到右依次是</p>

<ul>
<li>value</li>
<li>class</li>
<li>type</li>
<li>size</li>
<li>line</li>
<li>section</li>
<li>symbol-name</li>
</ul>

<h2 id="toc_1">elf64-x86-64 文件</h2>

<p><code>elf</code>是<code>Executable and Linkable Format</code>(可执行和可链接格式，<a href="http://larryim.cc/Linking.html">看本文</a>)的简称。<code>elf</code>文件格式及其复杂，如果只需要研究<code>objdump</code>产生的反汇编文件没有必要去专门学习<code>elf</code>格式。掌握下面几点，就可以阅读<code>objdump</code>产生的反汇编文件了。<code>objdump</code>产生的<code>elf</code>文件，主要包括以下几个部分：</p>

<ul>
<li>Disassembly of section .init</li>
<li>Disassembly of section .plt</li>
<li>Disassembly of section .text</li>
<li>Disassembly of section .fini</li>
</ul>

<p>下面是一个具体的文件，为了更简洁的展示，每一部分只保留了一小段内容：</p>

<pre><code class="language-text">ctarget:     file format elf64-x86-64


Disassembly of section .init:

0000000000400c48 &lt;_init&gt;:
  400c48:   48 83 ec 08             sub    $0x8,%rsp
  400c4c:   e8 6b 02 00 00          callq  400ebc &lt;call_gmon_start&gt;
  400c51:   48 83 c4 08             add    $0x8,%rsp
  400c55:   c3                      retq   

Disassembly of section .plt:

0000000000400cb0 &lt;strcpy@plt&gt;:
  400cb0:   ff 25 6a 33 20 00       jmpq   *0x20336a(%rip)        # 604020 &lt;_GLOBAL_OFFSET_TABLE_+0x38&gt;
  400cb6:   68 04 00 00 00          pushq  $0x4
  400cbb:   e9 a0 ff ff ff          jmpq   400c60 &lt;_init+0x18&gt;


Disassembly of section .text:

00000000004011ad &lt;main&gt;:
  4011bb:   be c5 1d 40 00          mov    $0x401dc5,%esi
  4011c0:   bf 0b 00 00 00          mov    $0xb,%edi
  4011c5:   e8 86 fb ff ff          callq  400d50 &lt;signal@plt&gt;
  4011cf:   bf 07 00 00 00       
  401384:   c3                      retq   


Disassembly of section .fini:

0000000000402d74 &lt;_fini&gt;:
  402d74:   48 83 ec 08             sub    $0x8,%rsp
  402d78:   48 83 c4 08             add    $0x8,%rsp
  402d7c:   c3                      retq   

</code></pre>

<p>其中<code>.fini</code>部分是有关进程结束的指令。<code>.init</code>部分是有关进程启动的指令，在<code>main()</code>函数执行前会执行。<code>PLT</code>代表<code>Procedure Linkage Table</code>(过程链接表),用来调用在链接阶段未知的外部函数/过程的，在运行时它会动态链接。所以最重要的内容都在<code>.text</code>部分中。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - 过程]]></title>
    <link href="http://larryim.cc/procedure.html"/>
    <updated>2018-07-12T10:43:40+08:00</updated>
    <id>http://larryim.cc/procedure.html</id>
    <content type="html"><![CDATA[
<p><strong>过程</strong>(procedure)是软件中一种很重要的抽象。它提供了一种封装代码的方式，用一组制定的参数和一个可选的返回值实现了某这功能。然后，可以在程序中不同的地方调用这个函数。不同编程语言中，过程的形式多样：函数(function)、方法(method)、子例程(subroutine)、处理函数(handler)等等。</p>

<p>假设过程P调用过程Q，Q执行后返回到P，包含下面一个或多个机制：</p>

<ul>
<li>传递控制。在进入过程Q的时候，程序计数器必须被设置为Q的代码的起始地址，然后在返回时，要把程序计数器设置为P中调用Q后面那条指令的地址。</li>
<li>传递数据。P必须能够向Q提供一个或多个参数，Q必须能够向P返回一个值。</li>
<li>分配和释放内存。在开始时，Q可能需要为局部变量分配空间，而在返回前，又必须释放这些存储空间。</li>
</ul>

<h2 id="toc_0">1 运行时栈</h2>

<p>在函数调用时，往往使用了栈(<code>Stack</code>)这一数据结构。当x86-64过程需要的存储空间超出寄存器能够存放的大小时(意味着其实很多函数根本不需要帧栈)，就会在栈上分配空间，称为<strong>帧栈</strong>(stack frame)。</p>

<p>Current Stack Frame (“Top” to Bottom) contains:</p>

<ul>
<li>Argument build(参数构造区):
<ul>
<li>Parameters for function about to call</li>
<li>可以通过寄存器最多传递6个整形参数，超出6个部分就要通过栈来传递</li>
</ul></li>
<li>Local variables(局部变量):
<ul>
<li>寄存器不足够存放所有的本地数据</li>
<li>使用地址运算符&amp;，必须能够产生一个地址</li>
</ul></li>
<li>Saved register context(被保存的寄存器)
<ul>
<li>保存寄存器的值到栈中</li>
</ul></li>
<li>Old frame pointer (optional)</li>
</ul>

<p><img src="media/15312146721582/stack_frame.png" alt="stack_frame"/></p>

<h2 id="toc_1">参考资料</h2>

<p>Randal E B, David O H. 2015. Computer Systems: A programmer&#39;s Perspective, 3rd.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - 虚拟内存]]></title>
    <link href="http://larryim.cc/virtual_memory_and_dynamic_memory_allocate.html"/>
    <updated>2018-01-20T07:09:22+08:00</updated>
    <id>http://larryim.cc/virtual_memory_and_dynamic_memory_allocate.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1 物理/虚拟寻址</h2>

<p>主存是由连续的<strong>字节大小</strong>的单元组成的数组，每字节都有一个唯一的<strong>物理地址</strong>(Physical Adress)。CPU使用物理地址访问内存的方式称为<strong>物理寻址</strong>(Physical adressing)。</p>

<p>早期的PC以及数字信号处理器等使用物理寻址，下面是物理寻址的示意图：</p>

<p><img src="media/15164033620970/physical_address.png" alt="physical_address"/></p>

<p>现代处理器通过生成一个<strong>虚拟地址</strong>(Virtual Address)来访问主存，虚拟地址经过<strong>地址翻译</strong>转换为物理地址。地址翻译由CPU内的<strong>内存管理单元</strong>(Memory Management Unit, <code>MMU</code>)负责.</p>

<p><img src="media/15164033620970/virtual_memory%20.png" alt="virtual_memory "/></p>

<p>虚拟内存充当着三个角色：</p>

<ul>
<li>作为缓存的工具，可以更有效率的使用内存：使用DRAM当做部分的虚拟地址空间的缓存</li>
<li>作为内存管理的工具，简化内存管理：每个进程都有统一的线性地址空间</li>
<li>作为内存保护的工具，分隔地址空间：进程的内存不会相互影响；用户程序不能访问保密的内核信息和代码</li>
</ul>

<p>下面一节具体讲解虚拟内存的这三个角色。</p>

<h2 id="toc_1">2 虚拟内存的三个角色</h2>

<h3 id="toc_2">2.1 作为缓存的工具</h3>

<p>可以把主存DRAM看作是虚拟内存的缓存，类似于L1、L2、L3高速缓存是DRAM内存的缓存。也就是说可以把虚拟内存看成是存储器层次结构的一部分。</p>

<p><img src="media/15164033620970/vm_as_cache.png" alt="vm_as_cache"/></p>

<p>和其他存储器层次结构中的缓存一样，较低层上的数据被分割成块，作为与较高层之间的传输单元。这里较低层是虚拟内存，分割成<strong>虚拟页</strong>(Virtual Page, VP)，虚拟页大小为\(P=2^p\)字节。类似的，这里的较高层，物理内存DRAM，被分割为<strong>物理页</strong>(Physical Page, PP)，大小也为\(P\)，也叫做页桢。</p>

<p>虚拟页的状态分为三种：</p>

<ul>
<li>未分配(Unallocated): 系统还未分配(创建)的页，不占用磁盘空间。</li>
<li>缓存的(Cached): 当前已缓存在物理内存中的已分配页。</li>
<li>未缓存的(Uncached): 未缓存在物理内存中的已分配页。</li>
</ul>

<p>那么具体是怎么判断一个虚拟页的状态呢？怎么知道虚拟页放在哪个物理页中呢？</p>

<p>物理内存中存在一个叫<strong>页表</strong>(page table)的数据结构，由操作系统负责。页表将虚拟页映射到物理页，每次内存管理单元中的<strong>地址翻译硬件</strong>将虚拟地址转换为物理地址时都会读取页表。</p>

<p>页表其实是一个页表条目(Page Table Entry, PTE)的数组。页表条目包含一个有效位(valid bit)和一个n位地址字段。</p>

<p><img src="media/15164033620970/page_table.jpg" alt="page_table"/></p>

<p>在虚拟内存的习惯说法中，DRAM缓存命中/不命中，特称为<strong>页命中</strong>/<strong>缺页</strong>(Page Fault)。</p>

<h3 id="toc_3">2.2 作为内存管理的工具</h3>

<p>操作系统为每个进程提供了一个独立的页表，也就是提供了一个独立的虚拟地址空间。多个虚拟页面可以映射到同一个共享物理页面上。虚拟内存简化了链接和加载、代码和数据共享、以及应用程序的内存分配。</p>

<h3 id="toc_4">2.3 作为内存保护的工具</h3>

<p>一方面，每个进程拥有独立的地址空间使得区分不同进程的私有内存变得容易。另一方面在每个页表条目PTE中，添加了额外的<strong>许可位</strong>(SUP, READ, WRITE, EXEC)来控制对一个虚拟页面内容的访问：</p>

<ul>
<li>SUP位表示进程是否运行在超级用户模式下才能访问</li>
<li>READ/WRITE位控制读和写的访问</li>
<li>EXEC位控制执行的访问</li>
</ul>

<p><img src="media/15164033620970/vm_protection.png" alt="vm_protection"/></p>

<p>如果违反许可条件，那么就触发段错误(segmentation fault)。</p>

<h2 id="toc_5">3 Linux虚拟内存系统</h2>

<p>Linux为每个进程维护了一个单独的虚拟地址空间。Linux将虚拟内存组织成一些<strong>区域</strong>的集合。一个区域就是已分配的虚拟内存的连续片。</p>

<p>Linux虚拟地址空间由如下几个区域组成：</p>

<ul>
<li>代码（<code>.text</code>）: 这里存放的是CPU要执行的指令。代码段是可共享的，相同的代码在内存中只会有一个拷贝，同时这个段是只读的，防止程序由于错误而修改自身的指令。</li>
<li>初始化数据段（<code>.data</code>）: 这里存放的是程序中需要明确赋初始值的变量，例如位于所有函数之外的全局变量：<code>int val=&quot;100</code>。需要强调的是，以上两段都是位于程序的可执行文件中，内核在调用<code>exec</code>函数启动该程序时从源程序文件中读入。</li>
<li>未初始化数据段（<code>.bss</code>）: 位于这一段中的数据，内核在执行该程序前，将其初始化为0或者<code>null</code>。例如出现在任何函数之外的全局变量：int sum;</li>
<li>堆（<code>Heap</code>）: 这个段用于在程序中进行动态内存申请，例如经常用到的<code>malloc</code>，<code>new</code>系列函数就是从这个段中申请内存。</li>
<li>共享库(<code>Shared Library</code>): 用来存放像C标准库和数学哭这样的共享库的代码和数据的区域。</li>
<li>栈（<code>Stack</code>）: 函数中的局部变量以及在函数调用过程中产生的临时变量都保存在此段中，具体见下面一节。</li>
<li>内核虚拟内存：包含内核中的代码和数据结构。</li>
</ul>

<p><img src="media/15089188725996/linux_virtual_memory.png" alt="linux_virtual_memory"/></p>

<h3 id="toc_6">3.1 Linux是如何组织虚拟内存的</h3>

<p>那么Linux具体是怎么组织虚拟内存的呢？Linux内核为系统中的每个进程维护一个单独的任务结构体(<code>task_struct</code>, 在<code>sched.h</code>头文件中)。<code>task_struct</code>中的元素包含运行该进程所需要的所有信息(PID、指向用户栈的指针、可执行目标文件的名字、以及程序计数器)。</p>

<p><img src="media/15164033620970/vm_linux.png" alt="vm_linux"/></p>

<p><code>task_struct</code>中的一个元素指向<code>mm_struct</code>，它描述了虚拟内存的当前状态。<code>pgd</code>指向第一级页表的基址，而<code>mmap</code>指向一个<code>vm_area_struct</code>(区域结构, 定义在<code>mm_types.h</code>)的链表。每个区域结构链表都描述了虚拟地址空间的一个区域，包含以下字段：</p>

<ul>
<li><code>vm_start</code>: 指向区域的起始处</li>
<li><code>vm_end</code>: 指向区域的结束处</li>
<li><code>vm_prot</code>: 描述着区域内包含的所有页的读写许可权限</li>
<li><code>vm_flags</code>: 描述进程共享/私有</li>
<li><code>vm_next</code>: 下一个区域结构</li>
</ul>

<h3 id="toc_7">3.2 Linux 缺页异常处理</h3>

<p>内存管理单元MMU在试图翻译某个虚拟地址A时，触发了一个缺页异常，引起缺页异常处理程序：</p>

<ul>
<li>虚拟地址A是合法的吗？-&gt; 段错误(segment fault)</li>
<li>试图进行的内存访问是合法的吗？ -&gt; 保护异常(也引发段错误)</li>
</ul>

<p><img src="media/15164033620970/linux_page_fault.png" alt="linux_page_fault"/></p>

<h2 id="toc_8">4 动态内存分配</h2>

<p>程序使用动态内存分配的最重要的原因是经常直到程序实际运行时，才知道某些数据结构的大小。一般使用动态内存分配器(dynamic memeory allocator)来分配动态内存。</p>

<p>分配器根据哪个实体来负责释放已分配的块，分为两种：</p>

<ul>
<li>显示分配器(explicit allocator)：要求程序显示地释放任何已分配的块。例如C中的malloc/free，C++中的new/delete。</li>
<li>隐式分配器(implicit allocator): 除此之外，自动释放未使用的已分配块(垃圾收集，garbage collection)。</li>
</ul>

<h3 id="toc_9">4.2 显式分配器的要求和目标</h3>

<h4 id="toc_10">4.2.1 分配器的要求</h4>

<p>分配器有如下的要求：</p>

<ul>
<li>处理任意请求序列</li>
<li>立即相应请求</li>
<li>只使用堆</li>
<li>对齐块(对齐要求)</li>
<li>不修改已分配的块</li>
</ul>

<h4 id="toc_11">4.2.2 分配器的目标</h4>

<p>分配器试图最大化吞吐率和内存利用率</p>

<ul>
<li>最大化吞吐率(吞吐率：每个单位时间里完成的请求数)</li>
<li>最大化内存利用率</li>
</ul>

<p>最大化吞吐率和最大化利用率之间是相互 <u>牵制</u> 的，分配器设计的目标是在这两者之间找到一个适当的平衡。</p>

<p>造成利用率很低的主要原因是<strong>碎片</strong>(fragmentation)现象。当有效载荷比块要小时，发生<strong>内部碎片</strong>(Internal fragmentation)，引起的原因有：对齐等。</p>

<p><img src="media/15164033620970/internal_fragmentation.png" alt="internal_fragmentation"/></p>

<p>当即使有足够的累积的块内存，但是没有单一块能够满足需求时，发生<strong>外部碎片</strong>(external fragmentation)：</p>

<p><img src="media/15164033620970/external_fragmentation.png" alt="external_fragmentation"/></p>

<p>外部碎片还取决于将来的请求，例如上图，如果最后的p4请求4个字节呢？也就不会发生碎片。正因为外部碎片难以量化且不可能预测，所以分配器通常采用启发式策略来试图维持少量的大空闲块，而不是维持大量的小空闲块。</p>

<h3 id="toc_12">4.3 实现方法</h3>

<ul>
<li>隐式空闲列表 Implicit Free List</li>
<li>显式空闲列表 Explicit Free List</li>
<li>分离式空闲列表 Segregated Free List</li>
</ul>

<h4 id="toc_13">4.3.1 隐式空闲列表</h4>

<p><img src="media/15164033620970/implicit_list.png" alt="implicit_list"/></p>

<p>隐式空闲链表优点是简单，缺点是操作开销大。因为无论是分配还是释放块，都需要对隐式空闲列表进行搜索，复杂度是\(O(n)\)，\(n\)是已分配块和空闲块的总数。</p>

<h4 id="toc_14">4.3.1 显式空闲列表</h4>

<p><img src="media/15164033620970/explict_list.png" alt="explict_list"/></p>

<h4 id="toc_15">4.3.1 分离式空闲列表</h4>

<h2 id="toc_16">5 C程序中常见的与内存有关的错误</h2>

<h4 id="toc_17">5.1 间接引用坏指针</h4>

<p>这是非常常见的例子，没有引用对应的地址，少了 &amp;</p>

<pre><code class="language-c">int val;
scanf(&quot;%d&quot;, val); // 正确应该是scanf(&quot;%d, &amp;val);
</code></pre>

<h4 id="toc_18">5.2 读未初始化的内存</h4>

<p><strong>堆内存是没有被初始化为0的</strong>：</p>

<pre><code class="language-c">/* return y = Ax */
int *matvec(int **A, int *x) {
    int *y = malloc(N * sizeof(int));
    int i, j;
    
    for (i = 0; i &lt; N; i++)
        for (j = 0; j &lt; N; j++)
            y[i] += A[i][j] * x[j];
    return y;
}
</code></pre>

<p>正确的方法是显式地将y[i]设置为0，或者使用<code>calloc</code>。</p>

<h4 id="toc_19">5.3 允许栈缓冲区溢出</h4>

<p>没有检查字符串的长度（经典的缓冲区溢出攻击也是利用相同的机制）</p>

<pre><code class="language-c">char s[8];
int i;
gets(s); /* stack buffer overflow, reads &quot;123456789&quot; from stdin */
</code></pre>

<h4 id="toc_20">5.4 引用不存在的变量</h4>

<p>尽管指针仍然指向一个合法的内存地址，但是已经不再指向一个合法的变量了。以后在程序中调用其他函数时，内存将重用它们的栈针。</p>

<pre><code class="language-c">int *foo() {
    int val;
    
    return &amp;val;
}
</code></pre>

<h4 id="toc_21">5.5 多次释放</h4>

<p>这个不用多说，不能重复搞两次</p>

<pre><code class="language-c">x = malloc(N * sizeof(int));
//  &lt;manipulate x&gt;
free(x);
y = malloc(M * sizeof(int));
//  &lt;manipulate y&gt;
free(x);
</code></pre>

<h4 id="toc_22">5.6 引用已经被释放的堆块中的数据</h4>

<p>同样是很明显的错误，不要犯</p>

<pre><code class="language-c">x = malloc(N * sizeof(int));
//  &lt;manipulate x&gt;
free(x);
//  ....
y = malloc(M * sizeof(int));
for (i = 0; i &lt; M; i++)
    y[i] = x[i]++;
</code></pre>

<h4 id="toc_23">内存泄漏</h4>

<p>5.7忘记释放已分配块：</p>

<pre><code class="language-c">foo() {
    int *x = malloc(N * sizeof(int));
    // ...
    return ;
}
</code></pre>

<p>或者只释放了数据结构的一部分：</p>

<pre><code class="language-c">struct list {
    int val;
    struct list *next;
};
foo() {
    struct list *head = malloc(sizeof(struct list));
    head-&gt;val = 0;
    head-&gt;next = NULL;
    //...
    free(head);
    return;
}
</code></pre>

<h2 id="toc_24">6 core i7内存系统</h2>

<p>Core i7在2008年冬季发布，基于全新Nehalem架构，它的芯片结构如下所示：</p>

<p><img src="media/15164033620970/15312857062358.png" alt=""/></p>

<p>抽象的内存系统：</p>

<p><img src="media/15164033620970/corei7.png" alt="corei7"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CSAPP - 存储器层次结构]]></title>
    <link href="http://larryim.cc/Computer_memory.html"/>
    <updated>2017-10-25T16:07:52+08:00</updated>
    <id>http://larryim.cc/Computer_memory.html</id>
    <content type="html"><![CDATA[
<p>存储器系统(memory system)是一个具有不同 <u>容量</u> 、 <u>成本</u> 和 <u>访问时间</u> 的存储设备的层次结构。</p>

<p><strong>局部性</strong>(locality)：具有良好局部性的程序倾向于一次又一次地访问相同的数据项集合，或是倾向于访问邻近的数据项集合。</p>

<h2 id="toc_0">1 存储技术</h2>

<h3 id="toc_1">1.1 RAM</h3>

<p>随机访问存储器(Random-Access Memory, RAM)分为两类：静态(SRAM)和动态(DRAM)的。SRAM比DRAM更快，但也贵得多。</p>

<h3 id="toc_2">1.2 磁盘</h3>

<p>磁盘是由盘片(platter)构成的。每个盘片如同切西瓜一样被“切”成一块一块的扇面，同时沿着半径的方向被划分成了一组同心圆(磁道, track)，每条磁道被扇面切成很多的扇形区域叫做扇区（sector, 扇区是从磁盘读出和写入信息的最小单位，包含相等数量的数据位，通常为512字节），不同盘片上的同半径磁道组成了柱面。</p>

<p><img src="media/15089188725996/15312767746205.jpg" alt=""/></p>

<p>磁盘的容量： 磁头数 × 磁道数 × 每道扇区数 × 每扇区字节数</p>

<h2 id="toc_3">2 局部性</h2>

<p>一个编写良好的计算机程序常常具有良好的局部性(locality)。也就是，它们倾向于引用邻近于其他最近引用过的数据项的数据项(空间局部性)，或者最近引用过的数据项本身(时间局部性)。</p>

<p>现代计算机系统的各个层次，从硬件到操作系统、再到应用程序，它们的设计都利用了局部性。</p>

<h2 id="toc_4">3 存储器层次结构 Memory Hierarchy</h2>

<p>一般而言，从高层往低层走，存储设备变得更慢、更便宜和更大。</p>

<p><img src="media/15128019428341/15128077150126.png" alt="存储器层次结构"/></p>

<h2 id="toc_5">虚拟内存 Virtual Memory</h2>

<p>虚拟内存(<code>Virtual Memory</code>)是一个抽象概念。它为每个进程提供了假象，即每个进程都在独占地使用内存。每个进程看到的内存都是一致的，称为虚拟地址空间<code>Virtual Address Space</code>.</p>

<p>虚拟内存在不同操作系统上有区别，以Linux系统为例,下面是<code>Linux  x86-64运行时的内存映像</code>。</p>

<p><img src="media/15089188725996/linux_virtual_memory.png" alt="linux_virtual_memory"/></p>

<p>虚拟地址空间由如下几部分组成：</p>

<ul>
<li>代码（<code>.text</code>）: 这里存放的是CPU要执行的指令。代码段是可共享的，相同的代码在内存中只会有一个拷贝，同时这个段是只读的，防止程序由于错误而修改自身的指令。</li>
<li>初始化数据段（<code>.data</code>）: 这里存放的是程序中需要明确赋初始值的变量，例如位于所有函数之外的全局变量：<code>int val=&quot;100</code>。需要强调的是，以上两段都是位于程序的可执行文件中，内核在调用<code>exec</code>函数启动该程序时从源程序文件中读入。</li>
<li>未初始化数据段（<code>.bss</code>）: 位于这一段中的数据，内核在执行该程序前，将其初始化为0或者<code>null</code>。例如出现在任何函数之外的全局变量：int sum;</li>
<li>堆（<code>Heap</code>）: 这个段用于在程序中进行动态内存申请，例如经常用到的<code>malloc</code>，<code>new</code>系列函数就是从这个段中申请内存。</li>
<li>共享库(<code>Shared Library</code>): 用来存放像C标准库和数学哭这样的共享库的代码和数据的区域。</li>
<li>栈（<code>Stack</code>）: 函数中的局部变量以及在函数调用过程中产生的临时变量都保存在此段中，具体见下面一节。</li>
<li>内核虚拟内存：包含内核中的代码和数据结构。</li>
</ul>

<p>注意：</p>

<ul>
<li>底部内存地址是最小的，越往上地址越大。</li>
<li>堆(正向增长)和栈(反向增长)的生长方向(箭头➡️所指方向)是相反的。</li>
</ul>

<p>下面是程序示意：</p>

<pre><code class="language-c"> #include&lt;stdio.h&gt;    
 #include &lt;malloc.h&gt;    
     
 void print(char *,int);    
 int main()    
{    
      char *s1 = &quot;abcde&quot;;  //&quot;abcde&quot;作为字符串常量存储在常量区 s1、s2、s5拥有相同的地址  
      char *s2 = &quot;abcde&quot;;    
      char s3[] = &quot;abcd&quot;;    
      long int *s4[100];    
      char *s5 = &quot;abcde&quot;;    
      int a = 5;    
      int b =6;//a,b在栈上，&amp;a&gt;&amp;b地址反向增长    
     
     printf(&quot;variables address in main function: s1=%p  s2=%p s3=%p s4=%p s5=%p a=%p b=%p \n&quot;,     
             s1,s2,s3,s4,s5,&amp;a,&amp;b);   
     printf(&quot;variables address in processcall:n&quot;);    
        print(&quot;ddddddddd&quot;,5);//参数入栈从右至左进行,p先进栈,str后进 &amp;p&gt;&amp;str    
     printf(&quot;main=%p print=%p \n&quot;,main,print);    
     //打印代码段中主函数和子函数的地址，编译时先编译的地址低，后编译的地址高main&lt;print    
 }    
  
 void print(char *str,int p)    
{    
     char *s1 = &quot;abcde&quot;;  //abcde在常量区，s1在栈上    
     char *s2 = &quot;abcde&quot;;  //abcde在常量区，s2在栈上 s2-s1=6可能等于0，编译器优化了相同的常量，只在内存保存一份    
     //而&amp;s1&gt;&amp;s2    
     char s3[] = &quot;abcdeee&quot;;//abcdeee在常量区，s3在栈上，数组保存的内容为abcdeee的一份拷贝    
     long int *s4[100];    
     char *s5 = &quot;abcde&quot;;    
     int a = 5;    
     int b =6;    
     int c;    
     int d;           //a,b,c,d均在栈上，&amp;a&gt;&amp;b&gt;&amp;c&gt;&amp;d地址反向增长    
     char *q=str;   
     int m=p;           
     char *r=(char *)malloc(1);    
     char *w=(char *)malloc(1) ;  // r&lt;w 堆正向增长    
    
     printf(&quot;s1=%p s2=%p s3=%p s4=%p s5=%p a=%p b=%p c=%p d=%p str=%p q=%p p=%p m=%p r=%p w=%p \n&quot;,    
            s1,s2,s3,s4,s5,&amp;a,&amp;b,&amp;c,&amp;d,&amp;str,q,&amp;p,&amp;m,r,w);   
     /* 栈和堆是在程序运行时候动态分配的，局部变量均在栈上分配。 
        栈是反向增长的，地址递减；malloc等分配的内存空间在堆空间。堆是正向增长的，地址递增。   
        r,w变量在栈上(则&amp;r&gt;&amp;w)，r,w所指内容在堆中(即r&lt;w)。*/   
 }    
   
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[内存对齐]]></title>
    <link href="http://larryim.cc/memory_alignment.html"/>
    <updated>2018-01-21T07:38:17+08:00</updated>
    <id>http://larryim.cc/memory_alignment.html</id>
    <content type="html"><![CDATA[
<p>许多计算机系统对基本数据类型的合法地址做出了一些限制， <u>要求某种类型对象的地址必须是某个值\(K\)(通常是2、4或8)的倍数</u> 。这种<strong>对齐限制</strong>简化了处理器和内存系统之间的硬件设计。例如，假设一个处理器总是从内存中取8个字节，则地址必须为8的倍数。如果我们能保证将所有的double类型的数据对齐成8的倍数，那么就可以用一个内存操作来读或者写值了。否则，我们可能需要执行两次内存访问，因为对象可能被放在两个8字节内存块中。</p>

<p>例如：</p>

<pre><code class="language-c">#include &lt;iostream&gt;
using namespace std;
struct A{
    char a;
    int b;
    short c;
};

struct B{
    short c;
    char a;
    int b;
};

int main(){
    cout&lt;&lt;sizeof(A)&lt;&lt;endl; //结果是12
    cout&lt;&lt;sizeof(B)&lt;&lt;endl; //结果是8
    return 0;
}
</code></pre>

<p>以上结构体变量数量和类型完全相同，但是因为对齐限制，却得到了不同的结果。具体为什么会这样，请参考下面的对齐原则。</p>

<h2 id="toc_0">对齐原则</h2>

<ul>
<li>任何\(K\)字节的基本对象的地址必须是K的倍数: \(\text{align}(x) = \text{sizeof}(x) = K\)</li>
<li>结构体内存对齐要求结构体内每一个成员变量都是内存对齐的；</li>
<li>结构体本身也要对齐。</li>
</ul>

<p>除此之外，程序员可自己指定数据的对齐大小，通过使用<code>pragma pack(x)</code>预处理命令，指定对齐大小为\(\text{pack_align}=x\)。只能指定\(2^n\)作为对齐大小，对于指定对齐大小为6、9、10这样的编译器不会理会。</p>

<pre><code class="language-c">#pragma pack(x)
//...
#pragma pack()
</code></pre>

<p>使用<code>pragma pack(x)</code>预处理命令后，对齐大小为</p>

<p>\[\text{align}(x) = \min(\text{sizeof}(x) , \text{pack_align})\] </p>

<p>即<code>sizeof(x)</code>和指定对齐大小哪个小，对齐大小就为哪个。</p>

<p>通过以下例子可以更好地掌握内存对齐原则：</p>

<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;assert.h&gt;
#include &lt;stddef.h&gt;


#pragma pack(1)
    //此处指定对齐大小为1
    //对于a，实际对齐大小为min(sizeof(int),1)=min(4,1)=1
    //对于b，实际对齐大小为min(sizeof(char),1)=min(1,1)=1
    //编译器会确保TEST_A首地址即a的地首址是1字节对齐的，此时a对齐
    //对于b，由于b要求首地址1字节对齐，这显然对于任何地址都合适，所以a,b都是对齐的
    //对于TEST_A数组，第一个TEST_A是对齐的（假设其地址为0），则第二个TEST_A的首地址为(0+5=5)，对于第二个TEST_A的两个变量a，b均对齐
    //OK,对齐合理。因此整个结构体的大小为5   
typedef struct TEST_A
{
    int a;
    char b;
} A;
#pragma  pack()


#pragma pack(2)
    //此处指定对齐大小为2
    //对于a，实际对齐大小为min(sizeof(int),2)=min(4,2)=2
    //对于b，实际对齐大小为min(sizeof(char),2)=min(1,2)=1
    //编译器会确保TEST_A首地址即a的地首址是2字节对齐的，此时a对齐
    //对于b，由于b要求首地址1字节对齐，这显然对于任何地址都合适，所以a,b都是对齐的
    //对于TEST_B数组，第一个TEST_B是对齐的（假设其地址为0），则第二个TEST_B的首地址为(0+5=5)，对于第二个TEST_B的变量a，显然地址5是不对齐于2字节的
    //因此，需要在TEST_B的变量b后面填充1字节，此时连续相连的TEST_B数组才会对齐
    //OK,对齐合理。因此整个结构体的大小为5+1=6
typedef struct TEST_B
{
    int a;
    char b;
} B;
#pragma  pack()

   
#pragma pack(4)
    //此处指定对齐大小为4
    //对于a，实际对齐大小为min(sizeof(int),2)=min(4,4)=4
    //对于b，实际对齐大小为min(sizeof(char),2)=min(1,4)=1
    //编译器会确保TEST_A首地址即a的地首址是4字节对齐的，此时a对齐
    //对于b，由于b要求首地址1字节对齐，这显然对于任何地址都合适，所以a,b都是对齐的
    //对于TEST_C数组，第一个TEST_C是对齐的（假设其地址为0），则第二个TEST_C的首地址为(0+5=5)，对于第二个TEST_C的变量a，显然地址5是不对齐于4字节的
    //因此，需要在TEST_C的变量b后面填充3字节，此时连续相连的TEST_C数组才会对齐
    //OK,对齐合理。因此整个结构体的大小为5+3=8
typedef struct TEST_C
{
    int a;
    char b;
} C;
#pragma  pack()


#pragma pack(8)
    //此处指定对齐大小为8
    //对于a，实际对齐大小为min(sizeof(int),8)=min(4,8)=4
    //对于b，实际对齐大小为min(sizeof(char),8)=min(1,8)=1
    //编译器会确保TEST_A首地址即a的地首址是4字节对齐的，此时a对齐
    //对于b，由于b要求首地址1字节对齐，这显然对于任何地址都合适，所以a,b都是对齐的
    //对于TEST_D数组，第一个TEST_D是对齐的（假设其地址为0），则第二个TEST_D的首地址为(0+5=5)，对于第二个TEST_D的变量a，显然地址5是不对齐于4字节的
    //因此，需要在TEST_D的变量b后面填充3字节，此时连续相连的TEST_D数组才会对齐
    //OK,对齐合理。因此整个结构体的大小为5+3=8
typedef struct TEST_D
{
    int a;
    char b;
} D;
#pragma  pack()



#pragma pack(8)
    //此处指定对齐大小为8
    //对于a，实际对齐大小为min(sizeof(int),8)=min(4,8)=4
    //对于b，实际对齐大小为min(sizeof(char),8)=min(1,8)=1
    //对于c，这是一个数组，数组的对齐大小与其单元一致，因而align(c)=align(double)=min(sizeof(double),8)=min(8,8)=8
    //对于d，实际对齐大小为min(sizeof(char),8)=min(1,8)=1
    //编译器会确保TEST_A首地址即a的地首址是4字节对齐的，此时a对齐
    //对于b，由于b要求首地址1字节对齐，这显然对于任何地址都合适，所以a,b都是对齐的
    //对于c，由于c要求首地址8字节对齐，因此前面的a+b=5，还要在c后面补上3个字节才能对齐
    //对于d，显而易见，任何地址均对齐，此时结构体大小为4+1+3+10*8+1=89
    //对于TEST_E数组，第一个TEST_E是对齐的（假设其地址为0），则第二个TEST_E的首地址为(0+89=89)，对于第二个TEST_E的变量a，显然地址89是不对齐于4字节的
    //因此，需要在TEST_E的变量d后面填充7字节，此时连续相连的TEST_E数组才会对齐 
    //(注意：此处不仅要确保下一个TEST_E的a,b变量对齐，还要确保c也对齐，所以这里不是填充3字节，而是填充7字节）
    //OK,对齐合理。因此整个结构体的大小为(4)+(1+3)+(10*8)+(1+7)=96
typedef struct TEST_E
{
    int a;
    char b;
    double c[10];
    char d;
} E;
#pragma  pack()

int main()
{
    A A1;
    B B1;
    C C1;
    D D1;
    E E1, E2;
    printf(&quot;A:%zu, %zu\n&quot;, sizeof(A1), sizeof(A1));
    printf(&quot;B:%zu\n&quot;, sizeof(B1));
    printf(&quot;C:%zu\n&quot;, sizeof(C1));
    printf(&quot;D:%zu\n&quot;, sizeof(D1));
    printf(&quot;E:%zu, %zu\n&quot;, sizeof(E1), sizeof(E2));

    return 0;
}
</code></pre>

<pre><code class="language-text">A:5, 5
B:6
C:8
D:8
E:96, 96
</code></pre>

<h2 id="toc_1">内存对齐原因</h2>

<p>可能你对内存印象是，内存是由一个个字节组成的：</p>

<p><img src="media/15164914975645/howProgrammersSeeMemory.jpg" alt=""/></p>

<p>但是很可惜，CPU却不是这么看待的：</p>

<p><img src="media/15164914975645/howProcessorsSeeMemory.jpg" alt=""/></p>

<p>内存读取是按块进行的，块的大小称为<strong>粒度</strong>（granularity)。实际上在存储器层次结构上的较低层向较高层传输数据的时候都是按块进行的。也就是说，数据从内存到寄存器，要经过诸多关卡(在core i7上，有L1、L2和L3高速缓存)，每个关卡都有不同的粒度。所以为了提高速度，不仅仅大的对象要保证对齐，连对象内部的数据，也需要对齐到2的幂。</p>

<p>以内存读取为例，我们仔细看看为什么内存不对齐会影响读取速度？</p>

<p>假设CPU要读取一个4字节大小的数据到寄存器中（假设内存读取粒度是4），分两种情况讨论：</p>

<ul>
<li>1.数据从0字节开始</li>
<li>2.数据从1字节开始</li>
</ul>

<p>当数据从0字节开始的时候，直接将0-3四个字节完全读取到寄存器，就算完成了。</p>

<p><img src="media/15164914975645/quadByteAccess.jpg" alt=""/></p>

<p>当数据从1字节开始的时候，问题很复杂，首先先将前4个字节读到寄存器，并再次读取4-7字节的数据进寄存器，接着把0字节，5、6、7字节的数据剔除，最后合并1、2、3、4字节的数据进寄存器，对一个内存未对齐的寄存器进行了这么多额外操作，大大降低了性能。</p>

<p><img src="media/15164914975645/unalignedAccess.jpg" alt=""/></p>

<h2 id="toc_2">参考</h2>

<ul>
<li>1. 深入理解计算机体系（第三版）</li>
<li>2. <a href="https://zh.wikipedia.org/zh-hans/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AF%B9%E9%BD%90">数据结构对齐 维基百科</a></li>
<li>3. <a href="https://www.cnblogs.com/xylc/p/3780907.html">https://www.cnblogs.com/xylc/p/3780907.html</a></li>
<li>4. <a href="https://www.cnblogs.com/jijiji/p/4854581.html">https://www.cnblogs.com/jijiji/p/4854581.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[回溯法和深度优先遍历]]></title>
    <link href="http://larryim.cc/15272289883847.html"/>
    <updated>2018-05-25T14:16:28+08:00</updated>
    <id>http://larryim.cc/15272289883847.html</id>
    <content type="html"><![CDATA[
<p>算法中常见的回溯法backtracking和深度优先搜索DFS比较相似，很多人也把它们当作相同的算法。那么它们真的相同吗？</p>

<p>其实回溯法是一种更广泛目的的算法，而DFS只是限于树，而且用了回溯法的思想[1]。</p>

<p>下面具体看看DFS和backtracking的概念和应用</p>

<h2 id="toc_0">DFS</h2>

<p>DFS定义(from wikipedia)：One starts at the root (selecting some node as the root in the graph case) and explores as far as possible along each branch before backtracking.</p>

<p>DFS定义(from Intro to algorithm, 3rd, page603): The strategy followed by depth-first search is, to search “deeper” in the graph whenever possible. Depth-first search explores edges out of the most recently discovered vertex \(v\) that still has unexplored edges leaving it. Once all of \(v\prime\)s edges have been explored, the search “backtracks” to explore edges leaving the vertex from which \(v\)  was discovered. This process continues until we have discovered all the vertices that are reachable from the original source vertex. </p>

<p>两个DFS的定义其实都提到了<code>backtrack</code>这个词，说明了DFS中已经用了backtracking的思想。</p>

<h2 id="toc_1">backtracking</h2>

<p>backtracking定义(from wikipedia): Backtracking is a general algorithm for finding all (or some) solutions to some computational problems, notably constraint satisfaction problems, that incrementally builds candidates to the solutions, and abandons a candidate (&quot;backtracks&quot;) as soon as it determines that the candidate cannot possibly be completed to a valid solution.</p>

<p>Pseudocode</p>

<pre><code class="language-text">procedure bt(c)
  if reject(P,c) then return
  if accept(P,c) then output(P,c)
  s ← first(P,c)
  while s ≠ Λ do
    bt(s)
    s ← next(P,s)
</code></pre>

<p>Leetcode：</p>

<ul>
<li><LeetCode > 78 / 90 Subsets （I / II）</li>
<li><LeetCode > 46. / 47. Permutations (I / II)</li>
<li><LeetCode > 17. Letter Combinations of a Phone Number</li>
<li><LeetCode > 22. Generate Parentheses</li>
</ul>

<p>回溯法采用试错的思想，它尝试分步的去解决一个问题。在分步解决问题的过程中，当它通过尝试发现现有的分步答案不能得到有效的正确的解答的时候，它将取消上一步甚至是上几步的计算，再通过其它的可能的分步解答再次尝试寻找问题的答案。回溯法通常用最简单的递归方法来实现，在反复重复上述的步骤后可能出现两种情况：</p>

<ul>
<li>找到一个可能存在的正确的答案</li>
<li>在尝试了所有可能的分步方法后宣告该问题没有答案</li>
</ul>

<p>在最坏的情况下，回溯法会导致一次复杂度为指数时间的计算。</p>

<h2 id="toc_2">Reference</h2>

<ul>
<li><a href="https://stackoverflow.com/questions/1294720/whats-the-difference-between-backtracking-and-depth-first-search">1. What&#39;s the difference between backtracking and depth first search?</a></li>
<li><a href="https://www.slideshare.net/johnnatan20/homework-5-44119081">2. AI - Backtracking vs Depth-First Search (DFS)</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[]]></title>
    <link href="http://larryim.cc/maze_recursion.html"/>
    <updated>2018-05-25T15:57:42+08:00</updated>
    <id>http://larryim.cc/maze_recursion.html</id>
    <content type="html"><![CDATA[
<p><img src="media/15272350628209/15272351029187.jpg" alt=""/></p>

<pre><code class="language-python">import turtle

PART_OF_PATH = &#39;O&#39;
TRIED = &#39;.&#39;
OBSTACLE = &#39;+&#39;
DEAD_END = &#39;-&#39;

class Maze:
    def __init__(self,mazeFileName):
        rowsInMaze = 0
        columnsInMaze = 0
        self.mazelist = []
        mazeFile = open(mazeFileName,&#39;r&#39;)
        rowsInMaze = 0
        for line in mazeFile:
            rowList = []
            col = 0
            for ch in line[:-1]:
                rowList.append(ch)
                if ch == &#39;S&#39;:
                    self.startRow = rowsInMaze
                    self.startCol = col
                col = col + 1
            rowsInMaze = rowsInMaze + 1
            self.mazelist.append(rowList)
            columnsInMaze = len(rowList)

        self.rowsInMaze = rowsInMaze
        self.columnsInMaze = columnsInMaze
        self.xTranslate = -columnsInMaze/2
        self.yTranslate = rowsInMaze/2
        self.t = turtle.Turtle()
        self.t.shape(&#39;turtle&#39;)
        self.wn = turtle.Screen()
        self.wn.setworldcoordinates(-(columnsInMaze-1)/2-.5,-(rowsInMaze-1)/2-.5,(columnsInMaze-1)/2+.5,(rowsInMaze-1)/2+.5)

    def drawMaze(self):
        self.t.speed(10)
        self.wn.tracer(0)
        for y in range(self.rowsInMaze):
            for x in range(self.columnsInMaze):
                if self.mazelist[y][x] == OBSTACLE:
                    self.drawCenteredBox(x+self.xTranslate,-y+self.yTranslate,&#39;orange&#39;)
        self.t.color(&#39;black&#39;)
        self.t.fillcolor(&#39;blue&#39;)
        self.wn.update()
        self.wn.tracer(1)

    def drawCenteredBox(self,x,y,color):
        self.t.up()
        self.t.goto(x-.5,y-.5)
        self.t.color(color)
        self.t.fillcolor(color)
        self.t.setheading(90)
        self.t.down()
        self.t.begin_fill()
        for i in range(4):
            self.t.forward(1)
            self.t.right(90)
        self.t.end_fill()

    def moveTurtle(self,x,y):
        self.t.up()
        self.t.setheading(self.t.towards(x+self.xTranslate,-y+self.yTranslate))
        self.t.goto(x+self.xTranslate,-y+self.yTranslate)

    def dropBreadcrumb(self,color):
        self.t.dot(10,color)

    def updatePosition(self,row,col,val=None):
        if val:
            self.mazelist[row][col] = val
        self.moveTurtle(col,row)

        if val == PART_OF_PATH:
            color = &#39;green&#39;
        elif val == OBSTACLE:
            color = &#39;red&#39;
        elif val == TRIED:
            color = &#39;black&#39;
        elif val == DEAD_END:
            color = &#39;red&#39;
        else:
            color = None

        if color:
            self.dropBreadcrumb(color)

    def isExit(self,row,col):
        return (row == 0 or
                row == self.rowsInMaze-1 or
                col == 0 or
                col == self.columnsInMaze-1 )

    def __getitem__(self,idx):
        return self.mazelist[idx]


def searchFrom(maze, startRow, startColumn):
    # try each of four directions from this point until we find a way out.
    # base Case return values:
    #  1. We have run into an obstacle, return false
    maze.updatePosition(startRow, startColumn)
    if maze[startRow][startColumn] == OBSTACLE :
        return False
    #  2. We have found a square that has already been explored
    if maze[startRow][startColumn] == TRIED or maze[startRow][startColumn] == DEAD_END:
        return False
    # 3. We have found an outside edge not occupied by an obstacle
    if maze.isExit(startRow,startColumn):
        maze.updatePosition(startRow, startColumn, PART_OF_PATH)
        return True
    maze.updatePosition(startRow, startColumn, TRIED)
    # Otherwise, use logical short circuiting to try each direction
    # in turn (if needed)
    found = searchFrom(maze, startRow-1, startColumn) or \
            searchFrom(maze, startRow+1, startColumn) or \
            searchFrom(maze, startRow, startColumn-1) or \
            searchFrom(maze, startRow, startColumn+1)
    if found:
        maze.updatePosition(startRow, startColumn, PART_OF_PATH)
    else:
        maze.updatePosition(startRow, startColumn, DEAD_END)
    return found


myMaze = Maze(&#39;maze2.txt&#39;)
myMaze.drawMaze()
myMaze.updatePosition(myMaze.startRow,myMaze.startCol)

searchFrom(myMaze, myMaze.startRow, myMaze.startCol)

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dynamic Programming (3): 0-1 Knapsack Problem]]></title>
    <link href="http://larryim.cc/Dynamic_Programming_Knapsack_Problem.html"/>
    <updated>2017-08-09T16:41:03+08:00</updated>
    <id>http://larryim.cc/Dynamic_Programming_Knapsack_Problem.html</id>
    <content type="html"><![CDATA[
<p>The most common problem being solved is the <code>0-1 knapsack problem</code>(0-1背包问题), which restricts the number \(w_i\) of copies of each kind of item to zero or one. Given a set of \(n\) items numbered from 1 up to \(n\), each with a weight \(w_i\) and a value \(v_i\), along with a maximum weight capacity \(W\),</p>

<p>\[\begin{equation}<br/>
\begin{split}<br/>
&amp;\text{maximize} \sum_{i=1}^nv_ix_i\\<br/>
&amp;\text{subject to} \sum_{i=1}^n w_ix_i \le W \quad \text{and} \quad x_i \in \{0,1\}\\<br/>
\end{split}<br/>
\end{equation}\]</p>

<p>Informally, the problem is to maximize the sum of the values of the items in the knapsack so that the sum of the weights is less than or equal to the knapsack&#39;s capacity.</p>

<p><img src="media/15022680636956/15207485328974.png" alt=""/></p>

<h2 id="toc_0">Bottom-up method</h2>

<h3 id="toc_1">Solving</h3>

<p>Assume \(w_i, w_2,..., w_n, W\) are strictly positive integers. Define \(m[i,w]\) to be the maximum value that can be attained with weight less than or equal to \(w\) using items up to \(i\) (first \(i\) items).</p>

<p>We can define \(m[i,w]\) recursively as follows:</p>

<ul>
<li>\(m[0, w]=0 \)</li>
<li>\(m[i,w]=m[i-1, w]\) \(if w_i &gt; w\) ( the new item is more than the current weight limit)</li>
<li>\(m[i,w]= max(m[i-1,w],m[i-1,w-w_i]+v_i\)) if \(w_i \le w\)</li>
</ul>

<p>The following is pseudo code for the dynamic program:</p>

<pre><code class="language-python">// Input:
// Values (stored in array v)
// Weights (stored in array w)
// Number of distinct items (n)
// Knapsack capacity (W)
  
for j from 0 to W do:
     m[0, j] := 0
  
for i from 1 to n do:
    for j from 0 to W do:
        if w[i] &gt; j then:
            m[i, j] := m[i-1, j]
        else:
            m[i, j] := max(m[i-1, j], m[i-1, j-w[i]] + v[i])
</code></pre>

<h3 id="toc_2">Implementation</h3>

<pre><code class="language-python">def knapsack01(value, weight, w_size):
    &quot;&quot;&quot;
    kanapsack01 solves a 0-1 knapsack problem,
    input: values(value) and weights(W) of items to put into knapsack ( size of which is w_size)
    output: the index of items that maximize the value of items putted in the knapsack
    the index of items counts from 0, and corresponding value
    &quot;&quot;&quot;
    n = len(value)  # the number of items
    # maximum value that can be attained with weight &lt;= weight using first i items
    m = np.zeros(shape=(n+1, w_size+1), dtype=int)
    for i in range(w_size+1):
        m[0, i] = 0

    if not isinstance(w_size, int):
        raise ValueError(&#39;knapsack_size should be an integer&#39;)

    for i in range(1, n+1):  # items
        for j in range(1, w_size+1):  # sizes
            if weight[i-1] &gt; j:
                m[i, j] = m[i - 1, j]
            else:
                m[i, j] = max(m[i - 1, j], m[i - 1, j - weight[i-1]] + value[i-1])

    max_val = m[-1, -1]
    items = set()

    while max_val &gt; 0 and i &gt; 0:
        if max_val - value[i-1] in m[i - 1, :]:
            max_val = max_val - value[i-1]
            items.add(i-1)
            i -= 1
        else:
            i -= 1
    return items, m[-1, -1]
</code></pre>

<h2 id="toc_3">top-down with memoization</h2>

<pre><code class="language-python">def knapsack01_recursive(hash_table, value, weight, i, j):
    # base case: when 1 items here
    if i == 1:
        if weight[i - 1] &lt; j:
            hash_table[(i, j)] = value[i - 1]
            return value[i - 1]
        else:
            hash_table[(i, j)] = 0
        return 0

    # sub-problem computed
    if (i, j) in hash_table:
        return hash_table[(i, j)]
    else:
        if weight[i - 1] &gt; j:
            # only case 1
            hash_table[(i, j)] = knapsack01_recursive(hash_table, value, weight, i - 1, j)
        else:
            #  case 1, item i-1 excluded
            case1 = knapsack01_recursive(hash_table, value, weight, i - 1, j)
            # case 2, item i-1 included
            case2 = knapsack01_recursive(hash_table, value, weight, i - 1, j - weight[i - 1]) + value[i - 1]
            hash_table[(i, j)] = max(case1, case2)

    return hash_table[(i, j)]
</code></pre>

<h2 id="toc_4">Reference</h2>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Knapsack_problem#cite_ref-plateau85_15-0">Knapsack Problem WIKIPEDIA</a></li>
<li><a href="https://stackoverflow.com/questions/5683066/knapsack-problem-classic">Knapsack problem Stack Overflow</a></li>
<li><a href="http://www.es.ele.tue.nl/education/5MC10/Solutions/knapsack.pdf">The knapsack Problem PPT</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[技巧：Coursera下载Jupyter notebook相关文件]]></title>
    <link href="http://larryim.cc/Coursera_notebook_jupyter.html"/>
    <updated>2018-02-16T21:10:09+08:00</updated>
    <id>http://larryim.cc/Coursera_notebook_jupyter.html</id>
    <content type="html"><![CDATA[
<p>在Coursera上课时，想要保存练习题，但是练习题却是以Jupyter notebook文件呈现的，而且为了运行Jupyter notebook还需要下载相关的图片、数据等等。但是下载这些文件往往只能手动点击下载，如果能够一次性下载完成该多好。</p>

<p>事实上有一种非常简单的方法可以直接下载。首先选择打开Jupyter notebook，例如点击</p>

<p><img src="media/15187866094632/open_notebook.png" alt="open_notebook"/></p>

<p>打开的网址为 <a href="">https://hub.coursera-notebooks.org/user/${user_token}/notebooks/....ipynb</a>。然后进入到notebook页面，即 <a href="">https://hub.coursera-notebooks.org/user/${user_token}/notebooks</a>，删去notebook后面的一长串地址即可。</p>

<p><img src="media/15187866094632/notebook.png" alt="notebook"/></p>

<p>然后选择New-Python3，新建一个Jupyter Notebook，然后填入命令<code>!tar cvfz allfiles.tar.gz *</code>压缩所有文件到<code>allfiles.tar.gz</code>。最后回到Notebook界面，选择下载即可。</p>

]]></content>
  </entry>
  
</feed>
